{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/Tinder_Millennial_Match/train_set_label.csv\")\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Tinder_Millennial_Match/test_set_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Segment type</th>\n",
       "      <th>Segment Description</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>It became a relationship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>292890.8970</td>\n",
       "      <td>web</td>\n",
       "      <td>Meridian, Idaho</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292887.9870</td>\n",
       "      <td>web</td>\n",
       "      <td>Meridian, Idaho</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292894.0656</td>\n",
       "      <td>gender</td>\n",
       "      <td>Meridian, Idaho</td>\n",
       "      <td>No</td>\n",
       "      <td>499.173606</td>\n",
       "      <td>0.225255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>292887.1180</td>\n",
       "      <td>web</td>\n",
       "      <td>Meridian, Idaho</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292893.6561</td>\n",
       "      <td>gender</td>\n",
       "      <td>Meridian, Idaho</td>\n",
       "      <td>No</td>\n",
       "      <td>455.925963</td>\n",
       "      <td>0.211360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID Segment type Segment Description Answer       Count  \\\n",
       "0  292890.8970          web     Meridian, Idaho     No    0.000000   \n",
       "1  292887.9870          web     Meridian, Idaho     No    0.000000   \n",
       "2  292894.0656       gender     Meridian, Idaho     No  499.173606   \n",
       "3  292887.1180          web     Meridian, Idaho     No    0.000000   \n",
       "4  292893.6561       gender     Meridian, Idaho     No  455.925963   \n",
       "\n",
       "   Percentage  It became a relationship  \n",
       "0    0.000000                         0  \n",
       "1    0.000000                         0  \n",
       "2    0.225255                         0  \n",
       "3    0.000000                         0  \n",
       "4    0.211360                         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row37_col1,#T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row39_col1,#T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row40_col1,#T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row42_col1,#T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row51_col1,#T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row53_col1,#T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row54_col1{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >456</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >It became a relationship</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0: 0, 1: 1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >(1896, 7)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >(1260, 55)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row12_col1\" class=\"data row12 col1\" >(569, 55)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row21_col1\" class=\"data row21 col1\" >4818</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row22_col1\" class=\"data row22 col1\" >simple</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row37_col1\" class=\"data row37 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row38_col1\" class=\"data row38 col1\" >0.100000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row39_col1\" class=\"data row39 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row40_col1\" class=\"data row40 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row41_col1\" class=\"data row41 col1\" >0.050000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row42_col1\" class=\"data row42 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row43_col1\" class=\"data row43 col1\" >0.900000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row44_col0\" class=\"data row44 col0\" >Clustering</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row44_col1\" class=\"data row44 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row45_col0\" class=\"data row45 col0\" >Clustering Iteration</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row45_col1\" class=\"data row45 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row46_col0\" class=\"data row46 col0\" >Polynomial Features</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row46_col1\" class=\"data row46 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row47_col0\" class=\"data row47 col0\" >Polynomial Degree</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row47_col1\" class=\"data row47 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row48_col0\" class=\"data row48 col0\" >Trignometry Features</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row48_col1\" class=\"data row48 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row49_col0\" class=\"data row49 col0\" >Polynomial Threshold</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row49_col1\" class=\"data row49 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row50_col0\" class=\"data row50 col0\" >Group Features</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row50_col1\" class=\"data row50 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row51_col0\" class=\"data row51 col0\" >Feature Selection</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row51_col1\" class=\"data row51 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row52_col0\" class=\"data row52 col0\" >Features Selection Threshold</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row52_col1\" class=\"data row52 col1\" >0.800000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row53_col0\" class=\"data row53 col0\" >Feature Interaction</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row53_col1\" class=\"data row53 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row54_col0\" class=\"data row54 col0\" >Feature Ratio</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row54_col1\" class=\"data row54 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row55_col0\" class=\"data row55 col0\" >Interaction Threshold</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row55_col1\" class=\"data row55 col1\" >0.010000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row56_col0\" class=\"data row56 col0\" >Fix Imbalance</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row57_col0\" class=\"data row57 col0\" >Fix Imbalance Method</td>\n",
       "                        <td id=\"T_4114b3fe_6f03_11eb_bdea_ec8eb54216c0row57_col1\" class=\"data row57 col1\" >SMOTE</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22cb0ac1df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pycaret = setup(data =train,combine_rare_levels = True,remove_multicollinearity = True, bin_numeric_features= ['Count','Percentage'], remove_outliers = True,\n",
    "                feature_selection = True,feature_interaction = True,\n",
    "                feature_ratio = True,target ='It became a relationship',session_id=456 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_6d052b16_6f03_11eb_bfee_ec8eb54216c0 th {\n",
       "          text-align: left;\n",
       "    }#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col4,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col0,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col7{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col1,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col2,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col5,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col6,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col7,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col3,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col4{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col8,#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col8{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  lightgrey;\n",
       "        }#T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col8{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }</style><table id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>        <th class=\"col_heading level0 col7\" >MCC</th>        <th class=\"col_heading level0 col8\" >TT (Sec)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9183</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9797</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.9057</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.8703</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8867</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8228</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col7\" class=\"data row0 col7\" >0.8243</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row0_col8\" class=\"data row0 col8\" >3.4990</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >et</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >Extra Trees Classifier</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9040</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.9631</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8832</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8525</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8665</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.7916</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col7\" class=\"data row1 col7\" >0.7931</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row1_col8\" class=\"data row1 col8\" >0.1730</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >gbc</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >Gradient Boosting Classifier</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9016</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.9741</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.9013</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8357</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8664</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.7887</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col7\" class=\"data row2 col7\" >0.7912</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row2_col8\" class=\"data row2 col8\" >0.1530</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9024</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9730</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8877</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8462</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.8650</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7887</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col7\" class=\"data row3 col7\" >0.7910</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row3_col8\" class=\"data row3 col8\" >0.2070</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9000</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9679</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8899</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8400</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8631</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.7845</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col7\" class=\"data row4 col7\" >0.7866</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row4_col8\" class=\"data row4 col8\" >0.1050</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >xgboost</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >Extreme Gradient Boosting</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.8905</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9733</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8609</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.8370</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8478</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.7624</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col7\" class=\"data row5 col7\" >0.7636</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row5_col8\" class=\"data row5 col8\" >0.5390</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >lightgbm</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.8889</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9719</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8542</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8387</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8454</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.7587</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col7\" class=\"data row6 col7\" >0.7599</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row6_col8\" class=\"data row6 col8\" >0.0790</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >dt</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >Decision Tree Classifier</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.8905</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.8798</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8340</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.8561</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8439</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.7596</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col7\" class=\"data row7 col7\" >0.7608</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row7_col8\" class=\"data row7 col8\" >0.0160</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >ridge</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >Ridge Classifier</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.8794</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8921</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.7959</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8399</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.7438</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col7\" class=\"data row8 col7\" >0.7486</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row8_col8\" class=\"data row8 col8\" >0.0150</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >lda</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >Linear Discriminant Analysis</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.8810</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >0.9603</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.8742</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.8077</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.8385</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.7445</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col7\" class=\"data row9 col7\" >0.7474</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row9_col8\" class=\"data row9 col8\" >0.0210</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >knn</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >K Neighbors Classifier</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.8778</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9656</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8497</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.8187</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8320</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.7362</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col7\" class=\"data row10 col7\" >0.7388</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row10_col8\" class=\"data row10 col8\" >0.0310</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >lr</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >Logistic Regression</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.8183</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.9042</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.9417</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.6763</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.7862</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.6359</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col7\" class=\"data row11 col7\" >0.6638</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row11_col8\" class=\"data row11 col8\" >0.6690</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row12\" class=\"row_heading level0 row12\" >nb</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col0\" class=\"data row12 col0\" >Naive Bayes</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col1\" class=\"data row12 col1\" >0.8024</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col2\" class=\"data row12 col2\" >0.8905</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col3\" class=\"data row12 col3\" >0.8521</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col4\" class=\"data row12 col4\" >0.6791</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col5\" class=\"data row12 col5\" >0.7536</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col6\" class=\"data row12 col6\" >0.5928</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col7\" class=\"data row12 col7\" >0.6063</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row12_col8\" class=\"data row12 col8\" >0.0160</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row13\" class=\"row_heading level0 row13\" >svm</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col0\" class=\"data row13 col0\" >SVM - Linear Kernel</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col1\" class=\"data row13 col1\" >0.7722</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col3\" class=\"data row13 col3\" >0.6972</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col4\" class=\"data row13 col4\" >0.7294</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col5\" class=\"data row13 col5\" >0.6478</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col6\" class=\"data row13 col6\" >0.4947</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col7\" class=\"data row13 col7\" >0.5370</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row13_col8\" class=\"data row13 col8\" >0.0200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col1\" class=\"data row14 col1\" >0.7595</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col2\" class=\"data row14 col2\" >0.6668</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col3\" class=\"data row14 col3\" >0.3496</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col4\" class=\"data row14 col4\" >0.9120</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col5\" class=\"data row14 col5\" >0.4814</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col6\" class=\"data row14 col6\" >0.3796</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col7\" class=\"data row14 col7\" >0.4545</td>\n",
       "                        <td id=\"T_6d052b16_6f03_11eb_bfee_ec8eb54216c0row14_col8\" class=\"data row14 col8\" >0.0190</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ca3863fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x22c9d6269a0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(sort = 'F1')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_08e3e362_6ef8_11eb_894d_ec8eb54216c0 th {\n",
       "          text-align: left;\n",
       "    }#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col0,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col4,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col7{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col1,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col2,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col3,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col5,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col6,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col7,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col4{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col8,#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col8{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  lightgrey;\n",
       "        }#T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col8{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }</style><table id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>        <th class=\"col_heading level0 col7\" >MCC</th>        <th class=\"col_heading level0 col8\" >TT (Sec)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9135</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9788</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.9096</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.8548</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8810</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8131</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col7\" class=\"data row0 col7\" >0.8146</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row0_col8\" class=\"data row0 col8\" >3.5280</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >et</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >Extra Trees Classifier</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9127</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.9692</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8895</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8678</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8775</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8098</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col7\" class=\"data row1 col7\" >0.8111</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row1_col8\" class=\"data row1 col8\" >0.1740</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >lightgbm</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9119</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.9775</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8804</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8725</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8756</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8074</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col7\" class=\"data row2 col7\" >0.8083</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row2_col8\" class=\"data row2 col8\" >0.0820</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9111</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9779</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8848</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8669</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.8752</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.8062</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col7\" class=\"data row3 col7\" >0.8070</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row3_col8\" class=\"data row3 col8\" >0.4740</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >gbc</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >Gradient Boosting Classifier</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9056</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9729</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8895</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8509</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8689</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.7952</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col7\" class=\"data row4 col7\" >0.7967</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row4_col8\" class=\"data row4 col8\" >0.1370</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >dt</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >Decision Tree Classifier</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9079</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.8980</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8646</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.8739</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8683</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.7976</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col7\" class=\"data row5 col7\" >0.7986</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row5_col8\" class=\"data row5 col8\" >0.0130</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9024</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9666</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8962</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8387</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8658</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.7892</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col7\" class=\"data row6 col7\" >0.7912</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row6_col8\" class=\"data row6 col8\" >0.0800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >rf</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >Random Forest Classifier</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9008</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9748</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8669</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.8536</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8597</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.7830</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col7\" class=\"data row7 col7\" >0.7836</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row7_col8\" class=\"data row7 col8\" >0.1710</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >knn</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >K Neighbors Classifier</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.8841</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9525</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8514</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8259</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8381</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.7480</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col7\" class=\"data row8 col7\" >0.7485</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row8_col8\" class=\"data row8 col8\" >0.0220</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >lr</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >Logistic Regression</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.8770</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >0.9453</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.8558</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.8088</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.8307</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.7343</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col7\" class=\"data row9 col7\" >0.7361</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row9_col8\" class=\"data row9 col8\" >0.8670</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >ridge</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >Ridge Classifier</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.8706</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8356</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.8072</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8199</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.7191</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col7\" class=\"data row10 col7\" >0.7208</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row10_col8\" class=\"data row10 col8\" >0.0110</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >lda</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >Linear Discriminant Analysis</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.8706</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.9432</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.8221</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.8156</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.8173</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.7173</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col7\" class=\"data row11 col7\" >0.7189</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row11_col8\" class=\"data row11 col8\" >0.0160</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row12\" class=\"row_heading level0 row12\" >nb</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col0\" class=\"data row12 col0\" >Naive Bayes</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col1\" class=\"data row12 col1\" >0.7984</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col2\" class=\"data row12 col2\" >0.8904</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col3\" class=\"data row12 col3\" >0.6300</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col4\" class=\"data row12 col4\" >0.7556</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col5\" class=\"data row12 col5\" >0.6678</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col6\" class=\"data row12 col6\" >0.5320</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col7\" class=\"data row12 col7\" >0.5458</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row12_col8\" class=\"data row12 col8\" >0.0130</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row13\" class=\"row_heading level0 row13\" >svm</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col0\" class=\"data row13 col0\" >SVM - Linear Kernel</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col1\" class=\"data row13 col1\" >0.7167</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col3\" class=\"data row13 col3\" >0.5972</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col4\" class=\"data row13 col4\" >0.5882</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col5\" class=\"data row13 col5\" >0.5525</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col6\" class=\"data row13 col6\" >0.3637</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col7\" class=\"data row13 col7\" >0.3816</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row13_col8\" class=\"data row13 col8\" >0.0140</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col1\" class=\"data row14 col1\" >0.7254</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col2\" class=\"data row14 col2\" >0.6918</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col3\" class=\"data row14 col3\" >0.5770</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col4\" class=\"data row14 col4\" >0.7242</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col5\" class=\"data row14 col5\" >0.5503</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col6\" class=\"data row14 col6\" >0.3807</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col7\" class=\"data row14 col7\" >0.4201</td>\n",
       "                        <td id=\"T_08e3e362_6ef8_11eb_894d_ec8eb54216c0row14_col8\" class=\"data row14 col8\" >0.0210</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c9c33fe20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x22c9d5a8c70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare_models(sort = 'F1')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0 th {\n",
       "          text-align: left;\n",
       "    }#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col0,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col3,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col7{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col1,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col4,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col5,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col6,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col7,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col2,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col3{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col8,#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col8{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  lightgrey;\n",
       "        }#T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col8{\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }</style><table id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>        <th class=\"col_heading level0 col7\" >MCC</th>        <th class=\"col_heading level0 col8\" >TT (Sec)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9246</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9809</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.9052</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.8867</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8943</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8358</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col7\" class=\"data row0 col7\" >0.8377</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row0_col8\" class=\"data row0 col8\" >0.1570</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9175</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.9803</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.9121</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8636</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8865</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8218</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col7\" class=\"data row1 col7\" >0.8234</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row1_col8\" class=\"data row1 col8\" >0.1880</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >catboost</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >CatBoost Classifier</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9175</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.9821</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.9142</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8609</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8865</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8218</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col7\" class=\"data row2 col7\" >0.8230</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row2_col8\" class=\"data row2 col8\" >6.5550</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >gbc</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >Gradient Boosting Classifier</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9167</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9798</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.9007</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8684</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.8836</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.8188</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col7\" class=\"data row3 col7\" >0.8198</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row3_col8\" class=\"data row3 col8\" >0.2830</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >lightgbm</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9159</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9812</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8963</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8713</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8828</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8172</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col7\" class=\"data row4 col7\" >0.8184</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row4_col8\" class=\"data row4 col8\" >0.1030</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >xgboost</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >Extreme Gradient Boosting</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9135</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9790</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8984</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.8642</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8799</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8124</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col7\" class=\"data row5 col7\" >0.8140</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row5_col8\" class=\"data row5 col8\" >0.3190</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9103</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9732</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8917</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8619</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8753</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8054</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col7\" class=\"data row6 col7\" >0.8071</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row6_col8\" class=\"data row6 col8\" >0.1090</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >dt</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >Decision Tree Classifier</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9103</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9030</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8782</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.8709</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8731</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8038</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col7\" class=\"data row7 col7\" >0.8055</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row7_col8\" class=\"data row7 col8\" >0.0180</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.8833</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9618</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8783</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8089</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8414</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.7494</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col7\" class=\"data row8 col7\" >0.7520</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row8_col8\" class=\"data row8 col8\" >0.0160</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >knn</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >K Neighbors Classifier</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.8698</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >0.9339</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.8536</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.7965</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.8226</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.7202</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col7\" class=\"data row9 col7\" >0.7229</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row9_col8\" class=\"data row9 col8\" >0.0270</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >ridge</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >Ridge Classifier</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.8238</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.7471</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.7532</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.7437</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.6104</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col7\" class=\"data row10 col7\" >0.6166</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row10_col8\" class=\"data row10 col8\" >0.0170</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.6849</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.6179</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.3902</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.5826</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.4641</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.2543</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col7\" class=\"data row11 col7\" >0.2660</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row11_col8\" class=\"data row11 col8\" >0.0220</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col1\" class=\"data row12 col1\" >0.6365</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col3\" class=\"data row12 col3\" >0.6337</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col4\" class=\"data row12 col4\" >0.6009</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col5\" class=\"data row12 col5\" >0.4490</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col6\" class=\"data row12 col6\" >0.2299</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col7\" class=\"data row12 col7\" >0.3320</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row12_col8\" class=\"data row12 col8\" >0.0200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col1\" class=\"data row13 col1\" >0.6563</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col2\" class=\"data row13 col2\" >0.7715</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col3\" class=\"data row13 col3\" >0.0338</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col4\" class=\"data row13 col4\" >0.6833</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col5\" class=\"data row13 col5\" >0.0639</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col6\" class=\"data row13 col6\" >0.0368</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col7\" class=\"data row13 col7\" >0.1060</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row13_col8\" class=\"data row13 col8\" >0.0130</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0level0_row14\" class=\"row_heading level0 row14\" >lr</th>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col0\" class=\"data row14 col0\" >Logistic Regression</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col1\" class=\"data row14 col1\" >0.6508</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col2\" class=\"data row14 col2\" >0.3332</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col3\" class=\"data row14 col3\" >0.0090</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col4\" class=\"data row14 col4\" >0.3000</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col5\" class=\"data row14 col5\" >0.0175</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col6\" class=\"data row14 col6\" >0.0116</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col7\" class=\"data row14 col7\" >0.0415</td>\n",
       "                        <td id=\"T_6643d8ae_6ef8_11eb_980f_ec8eb54216c0row14_col8\" class=\"data row14 col8\" >0.0140</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c9d5e1700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                     oob_score=False, random_state=456, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(sort = 'F1')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col0,#T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col1,#T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col2,#T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col3,#T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col4,#T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col5,#T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9127</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9799</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.8182</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.9231</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.8675</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8027</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8060</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.8889</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9712</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.8636</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8261</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8444</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.7581</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.7585</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9286</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9830</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.9091</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8889</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8989</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8437</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8438</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.8968</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9619</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9091</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8163</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8602</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7788</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7817</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9048</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9684</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9318</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8200</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8723</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.7969</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8010</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9444</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9868</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9091</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.9302</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.9195</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8771</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8773</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9206</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9864</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9556</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8431</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8958</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8321</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8364</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9524</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9922</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9333</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.9333</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9333</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8963</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8963</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9286</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9857</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.8444</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.9500</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8941</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8405</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8438</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9683</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9937</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >0.9778</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9362</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9565</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9315</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9321</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9246</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9809</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9052</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8867</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.8943</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8358</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8377</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0239</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0100</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0473</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0518</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0330</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0515</td>\n",
       "                        <td id=\"T_cc3eb1b2_6ef8_11eb_8c9c_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0507</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c9e900d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "et = create_model(estimator = 'et',fold =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col0,#T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col1,#T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col2,#T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col3,#T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col4,#T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col5,#T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9286</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9843</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9773</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8431</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.9053</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8484</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8544</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9286</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9763</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >1.0000</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8302</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.9072</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8500</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8597</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9365</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9803</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8462</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.9167</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8660</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8738</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.8968</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9623</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9318</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8039</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8632</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7811</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7866</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9127</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9814</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9318</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8367</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8817</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8129</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8158</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9524</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9897</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9773</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8958</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.9348</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8974</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8995</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9048</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9809</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9778</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8000</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8800</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8024</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8135</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9286</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9898</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9778</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8462</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9072</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8496</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8555</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9206</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9826</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9333</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8571</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8936</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8305</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8324</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9603</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9945</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9000</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9474</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9157</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9189</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9270</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9822</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9707</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8459</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.9037</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8454</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8510</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0187</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0084</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0268</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0312</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0242</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0392</td>\n",
       "                        <td id=\"T_968429bd_6ef9_11eb_8b76_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0384</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c9ea98f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune_et = tune_model(estimator = et,  fold = 10,  round = 4,  n_iter = 100, custom_grid = None,  optimize = 'Accuracy', choose_better = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col0,#T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col1,#T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col2,#T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col3,#T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col4,#T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col5,#T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9048</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9798</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.8864</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8478</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.8667</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.7926</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.7931</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.8968</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9767</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.8864</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8298</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8571</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.7765</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.7776</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9048</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9789</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.8864</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8478</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8667</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.7926</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.7931</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.9048</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9692</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9091</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8333</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8696</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7948</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7967</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9127</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9828</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9318</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8367</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8817</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8129</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8158</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9286</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9856</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9091</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8889</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.8989</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8437</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8438</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9048</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9800</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9333</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8235</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8750</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.7986</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8026</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9365</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9904</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9333</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8936</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9130</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8631</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8636</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9206</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9800</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9111</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8723</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8913</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8289</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8293</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9603</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9973</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >0.9556</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9348</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9451</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9140</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9141</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9175</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9821</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9142</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8609</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.8865</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8218</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8230</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0185</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0073</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0227</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0339</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0253</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0398</td>\n",
       "                        <td id=\"T_c2744c24_6ef9_11eb_916c_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0393</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c9e900eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbt = create_model(estimator = 'catboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col0,#T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col1,#T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col2,#T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col3,#T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col4,#T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col5,#T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9286</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9843</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9773</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8431</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.9053</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8484</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8544</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9286</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9763</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >1.0000</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8302</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.9072</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8500</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8597</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9365</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9803</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8462</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.9167</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8660</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8738</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.8968</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9623</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9318</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8039</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8632</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7811</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7866</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9127</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9814</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9318</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8367</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8817</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8129</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8158</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9524</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9897</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9773</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8958</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.9348</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8974</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8995</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9048</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9809</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9778</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8000</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8800</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8024</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8135</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9286</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9898</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9778</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8462</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9072</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8496</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8555</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9206</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9826</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9333</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8571</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8936</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8305</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8324</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9603</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9945</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9000</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9474</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9157</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9189</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9270</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9822</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9707</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8459</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.9037</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8454</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8510</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0187</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0084</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0268</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0312</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0242</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0392</td>\n",
       "                        <td id=\"T_e8673dfd_6efd_11eb_963c_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0384</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c9e8b5a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune_cbt = tune_model(estimator = et,  fold = 10,  round = 4,  n_iter = 100, custom_grid = None,  optimize = 'Accuracy', choose_better = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col0,#T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col1,#T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col2,#T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col3,#T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col4,#T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col5,#T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9286</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9789</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.8864</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.9070</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.8966</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8420</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8421</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9127</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9803</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.9091</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8511</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8791</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8109</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8120</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9286</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9831</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.9091</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8889</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8989</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8437</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8438</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.8889</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9687</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.8409</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8409</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8409</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7555</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7555</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.8889</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9803</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9318</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.7885</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8542</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.7654</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.7724</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9206</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9856</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.8636</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.9048</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.8837</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8235</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8240</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9127</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9775</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9333</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8400</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8842</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8145</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8174</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.8968</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9838</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.8667</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8478</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.8571</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.7764</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.7765</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9048</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9772</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.8667</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8667</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8667</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.7926</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.7926</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9762</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9967</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >0.9556</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9773</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9663</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9479</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9480</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9159</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9812</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.8963</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8713</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.8828</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8172</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8184</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0244</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0068</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0353</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0487</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0331</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0522</td>\n",
       "                        <td id=\"T_5efa667a_6efa_11eb_84ca_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0516</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ca02d6c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb = create_model(estimator = 'lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col0,#T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col1,#T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col2,#T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col3,#T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col4,#T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col5,#T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9286</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9843</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9773</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8431</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.9053</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8484</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8544</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9286</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9763</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >1.0000</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8302</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.9072</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8500</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8597</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9365</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9803</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8462</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.9167</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8660</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8738</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.8968</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9623</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9318</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8039</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8632</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7811</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7866</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9127</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9814</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9318</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8367</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8817</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8129</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8158</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9524</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9897</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9773</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8958</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.9348</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8974</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8995</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9048</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9809</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9778</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8000</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8800</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8024</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8135</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9286</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9898</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9778</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8462</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9072</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8496</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8555</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9206</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9826</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9333</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8571</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8936</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8305</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8324</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9603</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9945</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9000</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9474</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9157</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9189</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9270</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9822</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9707</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8459</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.9037</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8454</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8510</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0187</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0084</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0268</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0312</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0242</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0392</td>\n",
       "                        <td id=\"T_671062b9_6efd_11eb_9564_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0384</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ca18ba280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune_lgb = tune_model(estimator = et,  fold = 10,  round = 4,  n_iter = 100, custom_grid = None,  optimize = 'Accuracy', choose_better = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col0,#T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col1,#T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col2,#T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col3,#T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col4,#T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col5,#T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9206</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9771</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.8864</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8864</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.8864</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8254</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8254</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9127</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9807</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.9318</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8367</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8817</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8129</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8158</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.8968</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9760</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.8864</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8298</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8571</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.7765</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.7776</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.8889</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9620</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.8864</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8125</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8478</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7606</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7624</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9127</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9778</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9545</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8235</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8842</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8148</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8205</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9206</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9803</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.8864</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8864</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.8864</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8254</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8254</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9048</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9811</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9333</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8235</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8750</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.7986</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8026</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9286</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9903</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9111</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8913</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9011</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8452</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8453</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9286</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9818</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9111</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8913</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.9011</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8452</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8453</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9603</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9956</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >0.9333</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9545</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9438</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9132</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9133</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9175</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9803</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9121</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8636</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.8865</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8218</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8234</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0188</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0084</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0240</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0430</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0250</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0399</td>\n",
       "                        <td id=\"T_eeb278b7_6efa_11eb_8b24_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0392</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ca0370bb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = create_model(estimator = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col0,#T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col1,#T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col2,#T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col3,#T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col4,#T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col5,#T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9365</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9709</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9545</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8750</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.9130</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8632</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8652</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9286</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9532</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.9545</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8571</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.9032</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8469</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9127</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9709</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.9091</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8511</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8791</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8109</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8120</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.9286</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9392</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9545</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8571</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.9032</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.8469</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.8500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9048</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9818</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9545</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8077</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8750</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.7989</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8062</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9524</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9818</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9773</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8958</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.9348</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8974</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8995</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9365</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9797</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9556</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8776</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.9149</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8644</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8664</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9524</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9807</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >1.0000</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8824</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9375</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8993</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.9039</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9206</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9523</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9333</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8571</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8936</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8305</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8324</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9762</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9956</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9375</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9677</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9489</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9501</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9349</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9706</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9593</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8698</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.9122</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8607</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8636</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0200</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0164</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0263</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0319</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0269</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0427</td>\n",
       "                        <td id=\"T_e4a9b7af_6efc_11eb_b2d9_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0421</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c9ea25e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune_rf = tune_model(estimator = rf,  fold = 10,  round = 4,  n_iter = 100, custom_grid = None,  optimize = 'Accuracy', choose_better = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagged_et = ensemble_model(tune_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosted_et = ensemble_model(tune_et, method = 'Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col0,#T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col1,#T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col2,#T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col3,#T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col4,#T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col5,#T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9206</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9828</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9091</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8696</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.8889</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8272</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8277</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.8968</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9762</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.8864</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8298</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8571</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.7765</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.7776</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9048</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9780</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.8864</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8478</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8667</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.7926</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.7931</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.9127</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9611</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9091</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8511</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8791</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.8109</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.8120</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9127</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9874</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9545</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8235</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8842</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8148</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8205</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9603</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9843</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9773</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.9149</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.9451</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.9141</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.9153</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.8810</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9775</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9333</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.7778</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8485</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.7518</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.7603</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9444</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9855</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9778</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8800</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9263</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8819</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8851</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9127</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9749</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9111</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8542</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8817</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8127</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8137</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9762</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9947</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9375</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9677</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9489</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9501</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9222</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9802</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9345</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8586</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.8945</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8331</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8355</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0279</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0086</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0386</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0433</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0371</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0592</td>\n",
       "                        <td id=\"T_c0fd742b_6efe_11eb_aa2e_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0584</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ca359d1f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bagged_rf = ensemble_model(tune_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col0,#T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col1,#T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col2,#T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col3,#T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col4,#T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col5,#T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.8571</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9593</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.7955</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.7955</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.7955</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.6857</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.6857</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9048</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9739</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.8409</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8810</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.8605</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.7882</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.7887</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.8968</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9767</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.8182</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8780</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.8471</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.7694</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.7705</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.8651</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9537</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.8182</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8000</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8090</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7047</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7048</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.8810</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9593</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.8864</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.7959</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8387</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.7448</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.7475</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9206</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9881</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.8636</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.9048</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.8837</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8235</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8240</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.8968</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9772</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.8667</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8478</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8571</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.7764</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.7765</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9206</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9794</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.8667</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.9070</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.8864</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8254</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8259</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.8810</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9569</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.8000</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8571</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8276</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.7368</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.7379</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9444</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9874</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >0.9333</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9130</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9231</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.8796</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.8797</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.8968</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9712</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.8489</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8580</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.8529</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.7735</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.7741</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0256</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0122</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0407</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0445</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0363</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0560</td>\n",
       "                        <td id=\"T_34625093_6eff_11eb_8e3d_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0559</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ca3863fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boosted_rf = ensemble_model(tune_rf, method = 'Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col0,#T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col1,#T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col2,#T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col3,#T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col4,#T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col5,#T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9286</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9773</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8431</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.9053</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8484</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8544</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9286</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >1.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8302</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.9072</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8500</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8597</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9365</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8462</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.9167</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8660</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8738</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.8968</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9318</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8039</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8632</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7811</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.7866</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9127</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9318</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8367</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8817</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8129</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8158</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9524</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9773</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.8958</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.9348</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.8974</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.8995</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9048</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9778</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8800</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8024</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8135</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9286</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9778</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8462</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9072</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8496</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8555</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9206</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9333</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8571</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8936</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8305</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8324</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9603</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9474</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9157</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9189</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9270</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9707</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8459</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.9037</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8454</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8510</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0187</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0000</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0268</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0312</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0242</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0392</td>\n",
       "                        <td id=\"T_a4c668e9_6eff_11eb_8326_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0384</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ca03f3160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b1 = blend_models(estimator_list = [tune_cbt,tune_rf,tune_et],  fold = 10,  round = 4,  choose_better = False, optimize = 'Accuracy', method = 'hard', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col0,#T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col1,#T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col2,#T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col3,#T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col4,#T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col5,#T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row0_col0\" class=\"data row0 col0\" >0.9286</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row0_col1\" class=\"data row0 col1\" >0.9868</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row0_col2\" class=\"data row0 col2\" >0.9773</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row0_col3\" class=\"data row0 col3\" >0.8431</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row0_col4\" class=\"data row0 col4\" >0.9053</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row0_col5\" class=\"data row0 col5\" >0.8484</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row0_col6\" class=\"data row0 col6\" >0.8544</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row1_col0\" class=\"data row1 col0\" >0.9286</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row1_col1\" class=\"data row1 col1\" >0.9774</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row1_col2\" class=\"data row1 col2\" >0.9773</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row1_col3\" class=\"data row1 col3\" >0.8431</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row1_col4\" class=\"data row1 col4\" >0.9053</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row1_col5\" class=\"data row1 col5\" >0.8484</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row1_col6\" class=\"data row1 col6\" >0.8544</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row2_col0\" class=\"data row2 col0\" >0.9286</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row2_col1\" class=\"data row2 col1\" >0.9787</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row2_col2\" class=\"data row2 col2\" >0.9545</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row2_col3\" class=\"data row2 col3\" >0.8571</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row2_col4\" class=\"data row2 col4\" >0.9032</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row2_col5\" class=\"data row2 col5\" >0.8469</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row2_col6\" class=\"data row2 col6\" >0.8500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row3_col0\" class=\"data row3 col0\" >0.9048</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row3_col1\" class=\"data row3 col1\" >0.9692</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row3_col2\" class=\"data row3 col2\" >0.9318</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row3_col3\" class=\"data row3 col3\" >0.8200</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row3_col4\" class=\"data row3 col4\" >0.8723</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row3_col5\" class=\"data row3 col5\" >0.7969</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row3_col6\" class=\"data row3 col6\" >0.8010</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row4_col0\" class=\"data row4 col0\" >0.9127</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row4_col1\" class=\"data row4 col1\" >0.9810</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row4_col2\" class=\"data row4 col2\" >0.9545</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row4_col3\" class=\"data row4 col3\" >0.8235</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row4_col4\" class=\"data row4 col4\" >0.8842</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row4_col5\" class=\"data row4 col5\" >0.8148</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row4_col6\" class=\"data row4 col6\" >0.8205</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row5_col0\" class=\"data row5 col0\" >0.9603</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row5_col1\" class=\"data row5 col1\" >0.9886</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row5_col2\" class=\"data row5 col2\" >0.9773</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row5_col3\" class=\"data row5 col3\" >0.9149</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row5_col4\" class=\"data row5 col4\" >0.9451</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row5_col5\" class=\"data row5 col5\" >0.9141</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row5_col6\" class=\"data row5 col6\" >0.9153</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row6_col0\" class=\"data row6 col0\" >0.9206</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row6_col1\" class=\"data row6 col1\" >0.9870</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row6_col2\" class=\"data row6 col2\" >0.9778</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row6_col3\" class=\"data row6 col3\" >0.8302</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row6_col4\" class=\"data row6 col4\" >0.8980</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row6_col5\" class=\"data row6 col5\" >0.8337</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row6_col6\" class=\"data row6 col6\" >0.8412</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row7_col0\" class=\"data row7 col0\" >0.9286</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row7_col1\" class=\"data row7 col1\" >0.9905</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row7_col2\" class=\"data row7 col2\" >0.9778</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row7_col3\" class=\"data row7 col3\" >0.8462</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row7_col4\" class=\"data row7 col4\" >0.9072</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row7_col5\" class=\"data row7 col5\" >0.8496</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row7_col6\" class=\"data row7 col6\" >0.8555</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row8_col0\" class=\"data row8 col0\" >0.9206</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row8_col1\" class=\"data row8 col1\" >0.9829</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row8_col2\" class=\"data row8 col2\" >0.9333</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row8_col3\" class=\"data row8 col3\" >0.8571</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row8_col4\" class=\"data row8 col4\" >0.8936</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row8_col5\" class=\"data row8 col5\" >0.8305</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row8_col6\" class=\"data row8 col6\" >0.8324</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row9_col0\" class=\"data row9 col0\" >0.9762</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row9_col1\" class=\"data row9 col1\" >0.9968</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row9_col3\" class=\"data row9 col3\" >0.9375</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row9_col4\" class=\"data row9 col4\" >0.9677</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row9_col5\" class=\"data row9 col5\" >0.9489</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row9_col6\" class=\"data row9 col6\" >0.9501</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col0\" class=\"data row10 col0\" >0.9310</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col1\" class=\"data row10 col1\" >0.9839</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col2\" class=\"data row10 col2\" >0.9662</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col3\" class=\"data row10 col3\" >0.8573</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col4\" class=\"data row10 col4\" >0.9082</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col5\" class=\"data row10 col5\" >0.8532</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row10_col6\" class=\"data row10 col6\" >0.8575</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row11_col0\" class=\"data row11 col0\" >0.0204</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row11_col1\" class=\"data row11 col1\" >0.0074</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row11_col2\" class=\"data row11 col2\" >0.0208</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row11_col3\" class=\"data row11 col3\" >0.0368</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row11_col4\" class=\"data row11 col4\" >0.0267</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row11_col5\" class=\"data row11 col5\" >0.0430</td>\n",
       "                        <td id=\"T_5dc96c2e_6f02_11eb_893a_ec8eb54216c0row11_col6\" class=\"data row11 col6\" >0.0418</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22caecde1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b2 = blend_models(estimator_list = [tune_cbt,tune_rf,tune_et,tune_lgb],  fold = 10,  round = 4,  choose_better = False, optimize = 'Accuracy', method = 'soft', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       0\n",
       " 1       0\n",
       " 2       0\n",
       " 3       0\n",
       " 4       0\n",
       "        ..\n",
       " 1891    0\n",
       " 1892    0\n",
       " 1893    0\n",
       " 1894    0\n",
       " 1895    0\n",
       " Name: It became a relationship, Length: 1896, dtype: int64,\n",
       " 1097    0\n",
       " 1745    1\n",
       " 1596    0\n",
       " 265     1\n",
       " 248     1\n",
       "        ..\n",
       " 495     1\n",
       " 42      0\n",
       " 601     0\n",
       " 1707    0\n",
       " 613     0\n",
       " Name: It became a relationship, Length: 1260, dtype: int32,\n",
       " -1,\n",
       " {'acc': <pycaret.containers.metrics.classification.AccuracyMetricContainer at 0x22ca18add30>,\n",
       "  'auc': <pycaret.containers.metrics.classification.ROCAUCMetricContainer at 0x22ca18ade50>,\n",
       "  'recall': <pycaret.containers.metrics.classification.RecallMetricContainer at 0x22ca18adfd0>,\n",
       "  'precision': <pycaret.containers.metrics.classification.PrecisionMetricContainer at 0x22ca18ad610>,\n",
       "  'f1': <pycaret.containers.metrics.classification.F1MetricContainer at 0x22ca18adaf0>,\n",
       "  'kappa': <pycaret.containers.metrics.classification.KappaMetricContainer at 0x22ca18adb50>,\n",
       "  'mcc': <pycaret.containers.metrics.classification.MCCMetricContainer at 0x22ca18ad370>},\n",
       "       Count_3.0  Percentage_11.0  \\\n",
       " 1097        0.0              0.0   \n",
       " 1745        0.0              0.0   \n",
       " 1596        1.0              0.0   \n",
       " 265         0.0              0.0   \n",
       " 248         0.0              0.0   \n",
       " ...         ...              ...   \n",
       " 495         0.0              0.0   \n",
       " 42          0.0              0.0   \n",
       " 601         0.0              0.0   \n",
       " 1707        0.0              0.0   \n",
       " 613         0.0              0.0   \n",
       " \n",
       "       Segment Description_University of Notre Dame  Segment type_mobile  \\\n",
       " 1097                                           0.0                  0.0   \n",
       " 1745                                           0.0                  0.0   \n",
       " 1596                                           0.0                  0.0   \n",
       " 265                                            0.0                  0.0   \n",
       " 248                                            0.0                  0.0   \n",
       " ...                                            ...                  ...   \n",
       " 495                                            0.0                  0.0   \n",
       " 42                                             0.0                  0.0   \n",
       " 601                                            0.0                  1.0   \n",
       " 1707                                           0.0                  0.0   \n",
       " 613                                            0.0                  1.0   \n",
       " \n",
       "       Count_6.0  Count_11.0  Percentage_2.0  Count_4.0  \\\n",
       " 1097        0.0         0.0             0.0        0.0   \n",
       " 1745        0.0         0.0             0.0        0.0   \n",
       " 1596        0.0         0.0             0.0        0.0   \n",
       " 265         0.0         0.0             0.0        0.0   \n",
       " 248         0.0         0.0             0.0        0.0   \n",
       " ...         ...         ...             ...        ...   \n",
       " 495         0.0         0.0             0.0        0.0   \n",
       " 42          0.0         0.0             0.0        0.0   \n",
       " 601         0.0         1.0             0.0        0.0   \n",
       " 1707        0.0         0.0             0.0        0.0   \n",
       " 613         0.0         0.0             1.0        0.0   \n",
       " \n",
       "       Segment Description_Whatsgoodly University  Count_0.0  ...  \\\n",
       " 1097                                         0.0        0.0  ...   \n",
       " 1745                                         0.0        1.0  ...   \n",
       " 1596                                         0.0        0.0  ...   \n",
       " 265                                          0.0        1.0  ...   \n",
       " 248                                          0.0        1.0  ...   \n",
       " ...                                          ...        ...  ...   \n",
       " 495                                          0.0        1.0  ...   \n",
       " 42                                           0.0        1.0  ...   \n",
       " 601                                          0.0        0.0  ...   \n",
       " 1707                                         0.0        0.0  ...   \n",
       " 613                                          0.0        0.0  ...   \n",
       " \n",
       "       ID_multiply_Segment type_mobile  ID_multiply_Count_0.0  \\\n",
       " 1097                            0.000                0.00000   \n",
       " 1745                            0.000           293006.96875   \n",
       " 1596                            0.000                0.00000   \n",
       " 265                             0.000           293717.25000   \n",
       " 248                             0.000           293669.00000   \n",
       " ...                               ...                    ...   \n",
       " 495                             0.000           293676.65625   \n",
       " 42                              0.000           292890.62500   \n",
       " 601                        292882.750                0.00000   \n",
       " 1707                            0.000                0.00000   \n",
       " 613                        292881.125                0.00000   \n",
       " \n",
       "       sin(Percentage)_divide_Count_Power2  ID_divide_Count_Power2  \\\n",
       " 1097                         1.144707e-06                1.121155   \n",
       " 1745                         3.304094e-04              187.921280   \n",
       " 1596                         8.009666e-07                0.902167   \n",
       " 265                          0.000000e+00                0.000000   \n",
       " 248                          0.000000e+00                0.000000   \n",
       " ...                                   ...                     ...   \n",
       " 495                          1.510835e-01           430553.437500   \n",
       " 42                           0.000000e+00                0.000000   \n",
       " 601                          1.364288e-07                0.087313   \n",
       " 1707                         3.472119e-07                0.227375   \n",
       " 613                          2.952058e-07                0.384994   \n",
       " \n",
       "       Answer_No_multiply_Segment type_mobile  ID_multiply_Count_Power2  \\\n",
       " 1097                                     0.0              7.652064e+10   \n",
       " 1745                                     0.0              4.568566e+08   \n",
       " 1596                                     0.0              9.509206e+10   \n",
       " 265                                      0.0              0.000000e+00   \n",
       " 248                                      0.0              0.000000e+00   \n",
       " ...                                      ...                       ...   \n",
       " 495                                      0.0              2.003142e+05   \n",
       " 42                                       0.0              0.000000e+00   \n",
       " 601                                      1.0              9.824440e+11   \n",
       " 1707                                     0.0              3.772910e+11   \n",
       " 613                                      1.0              2.228067e+11   \n",
       " \n",
       "       Count_Power2_divide_tan(ID)  sin(Percentage)_multiply_ID  \\\n",
       " 1097                -6.050388e+04                 87593.671875   \n",
       " 1745                 3.334355e+04                150949.718750   \n",
       " 1596                 6.372099e+05                 76165.570312   \n",
       " 265                  0.000000e+00                     0.000000   \n",
       " 248                 -0.000000e+00                     0.000000   \n",
       " ...                           ...                          ...   \n",
       " 495                  1.052553e+00                 30264.179688   \n",
       " 42                  -0.000000e+00                     0.000000   \n",
       " 601                  2.659296e+05                134033.687500   \n",
       " 1707                -1.530321e+06                130999.937500   \n",
       " 613                 -5.672445e+06                 65773.828125   \n",
       " \n",
       "       ID_multiply_Answer_No  tan(ID)_multiply_Count_0.0  \n",
       " 1097           292901.90625                   -0.000000  \n",
       " 1745           293006.96875                    0.046762  \n",
       " 1596           292897.43750                    0.000000  \n",
       " 265                 0.00000                    0.340334  \n",
       " 248            293669.00000                   -1.025675  \n",
       " ...                     ...                         ...  \n",
       " 495                 0.00000                    0.648035  \n",
       " 42             292890.62500                   -0.058160  \n",
       " 601            292882.75000                    0.000000  \n",
       " 1707           292893.12500                   -0.000000  \n",
       " 613            292881.12500                   -0.000000  \n",
       " \n",
       " [1260 rows x 69 columns],\n",
       " 687     0\n",
       " 547     0\n",
       " 1762    0\n",
       " 1715    1\n",
       " 683     1\n",
       "        ..\n",
       " 629     0\n",
       " 1260    0\n",
       " 970     0\n",
       " 1864    0\n",
       " 827     0\n",
       " Name: It became a relationship, Length: 569, dtype: int64,\n",
       " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x22ca1904d30>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x22ca18d3970>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x22ca18d3d90>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x22ca18d3190>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x22ca18d3a30>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x22ca191c7f0>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x22ca191c730>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x22ca191ce80>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x22ca191c130>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x22ca191cd30>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x22ca18f7370>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x22ca18f7e50>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x22ca18f7a90>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x22ca18f7af0>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x22ca1904f10>,\n",
       "  'xgboost': <pycaret.containers.models.classification.XGBClassifierContainer at 0x22ca1904610>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x22ca18c73d0>,\n",
       "  'catboost': <pycaret.containers.models.classification.CatBoostClassifierContainer at 0x22ca18ba190>,\n",
       "  'Bagging': <pycaret.containers.models.classification.BaggingClassifierContainer at 0x22ca18ba5b0>,\n",
       "  'Stacking': <pycaret.containers.models.classification.StackingClassifierContainer at 0x22ca18ad490>,\n",
       "  'Voting': <pycaret.containers.models.classification.VotingClassifierContainer at 0x22ca18ad8b0>,\n",
       "  'CalibratedCV': <pycaret.containers.models.classification.CalibratedClassifierCVContainer at 0x22ca18adcd0>},\n",
       " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x22c9e951c70>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x22c9ea82b50>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x22c9ea822b0>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x22c9d5a8730>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x22c9d5a8dc0>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x22ca02edc70>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x22c9e8e3190>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x22ca19107f0>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x22ca19105b0>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x22ca19100d0>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x22c9e90ed30>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x22c9e90e490>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x22ca18ebd30>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x22ca18eb550>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x22ca18eb370>,\n",
       "  'xgboost': <pycaret.containers.models.classification.XGBClassifierContainer at 0x22ca18ebf70>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x22ca18df2b0>,\n",
       "  'catboost': <pycaret.containers.models.classification.CatBoostClassifierContainer at 0x22ca1904cd0>},\n",
       " 10,\n",
       " 'c354',\n",
       " 'It became a relationship',\n",
       " Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False),\n",
       " 'box-cox',\n",
       " True,\n",
       "                ID Segment type Segment Description Answer        Count  \\\n",
       " 0     292890.8970          web     Meridian, Idaho     No     0.000000   \n",
       " 1     292887.9870          web     Meridian, Idaho     No     0.000000   \n",
       " 2     292894.0656       gender     Meridian, Idaho     No   499.173606   \n",
       " 3     292887.1180          web     Meridian, Idaho     No     0.000000   \n",
       " 4     292893.6561       gender     Meridian, Idaho     No   455.925963   \n",
       " ...           ...          ...                 ...    ...          ...   \n",
       " 1891  292887.5496          web     Meridian, Idaho     No     0.000000   \n",
       " 1892  292881.6932       mobile     Meridian, Idaho     No  1203.190399   \n",
       " 1893  292900.8499       gender     Meridian, Idaho     No   806.378820   \n",
       " 1894  292893.8600       gender     Meridian, Idaho     No  1149.529381   \n",
       " 1895  292890.2944          web     Meridian, Idaho     No     0.000000   \n",
       " \n",
       "       Percentage  It became a relationship  \n",
       " 0       0.000000                         0  \n",
       " 1       0.000000                         0  \n",
       " 2       0.225255                         0  \n",
       " 3       0.000000                         0  \n",
       " 4       0.211360                         0  \n",
       " ...          ...                       ...  \n",
       " 1891    0.000000                         0  \n",
       " 1892    0.312360                         0  \n",
       " 1893    0.488025                         0  \n",
       " 1894    0.488984                         0  \n",
       " 1895    0.000000                         0  \n",
       " \n",
       " [1896 rows x 7 columns],\n",
       " False,\n",
       " False,\n",
       " {'parameter': 'Hyperparameters',\n",
       "  'auc': 'AUC',\n",
       "  'confusion_matrix': 'Confusion Matrix',\n",
       "  'threshold': 'Threshold',\n",
       "  'pr': 'Precision Recall',\n",
       "  'error': 'Prediction Error',\n",
       "  'class_report': 'Class Report',\n",
       "  'rfe': 'Feature Selection',\n",
       "  'learning': 'Learning Curve',\n",
       "  'manifold': 'Manifold Learning',\n",
       "  'calibration': 'Calibration Curve',\n",
       "  'vc': 'Validation Curve',\n",
       "  'dimension': 'Dimensions',\n",
       "  'feature': 'Feature Importance',\n",
       "  'feature_all': 'Feature Importance (All)',\n",
       "  'boundary': 'Decision Boundary',\n",
       "  'lift': 'Lift Chart',\n",
       "  'gain': 'Gain Chart',\n",
       "  'tree': 'Decision Tree'},\n",
       " [      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.6508  0.4494  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  1       0.6587  0.3445  0.0227  1.0000  0.0444  0.0294  0.1221\n",
       "  2       0.6508  0.3420  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  3       0.6508  0.2722  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  4       0.6667  0.2985  0.0455  1.0000  0.0870  0.0584  0.1734\n",
       "  5       0.6508  0.3495  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  6       0.6429  0.3373  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  7       0.6429  0.2845  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  8       0.6429  0.2922  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  9       0.6508  0.3623  0.0222  1.0000  0.0435  0.0284  0.1200\n",
       "  Mean    0.6508  0.3332  0.0090  0.3000  0.0175  0.0116  0.0415\n",
       "  SD      0.0071  0.0488  0.0150  0.4583  0.0289  0.0193  0.0649,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8810  0.9412  0.9091  0.7843  0.8421  0.7474  0.7526\n",
       "  1       0.8889  0.9374  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.8492  0.9004  0.8182  0.7660  0.7912  0.6734  0.6743\n",
       "  3       0.8333  0.8926  0.8182  0.7347  0.7742  0.6427  0.6451\n",
       "  4       0.8492  0.9358  0.8409  0.7551  0.7957  0.6767  0.6792\n",
       "  5       0.8254  0.9109  0.8636  0.7037  0.7755  0.6351  0.6440\n",
       "  6       0.8730  0.9380  0.8889  0.7843  0.8333  0.7314  0.7352\n",
       "  7       0.9206  0.9483  0.9111  0.8723  0.8913  0.8289  0.8293\n",
       "  8       0.8889  0.9616  0.8222  0.8605  0.8409  0.7556  0.7561\n",
       "  9       0.8889  0.9726  0.8000  0.8780  0.8372  0.7531  0.7550\n",
       "  Mean    0.8698  0.9339  0.8536  0.7965  0.8226  0.7202  0.7229\n",
       "  SD      0.0282  0.0243  0.0379  0.0572  0.0354  0.0581  0.0569,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.6587  0.7544  0.0227  1.0000  0.0444  0.0294  0.1221\n",
       "  1       0.6667  0.8426  0.0455  1.0000  0.0870  0.0584  0.1734\n",
       "  2       0.6587  0.7514  0.0455  0.6667  0.0851  0.0424  0.1040\n",
       "  3       0.6587  0.7885  0.0227  1.0000  0.0444  0.0294  0.1221\n",
       "  4       0.6746  0.7253  0.0682  1.0000  0.1277  0.0870  0.2132\n",
       "  5       0.6508  0.7184  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  6       0.6429  0.7959  0.0444  0.5000  0.0816  0.0248  0.0540\n",
       "  7       0.6508  0.7763  0.0444  0.6667  0.0833  0.0405  0.1009\n",
       "  8       0.6429  0.8198  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "  9       0.6587  0.7429  0.0444  1.0000  0.0851  0.0564  0.1704\n",
       "  Mean    0.6563  0.7715  0.0338  0.6833  0.0639  0.0368  0.1060\n",
       "  SD      0.0094  0.0384  0.0208  0.3833  0.0389  0.0252  0.0678,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9365  0.9249  0.8864  0.9286  0.9070  0.8588  0.8594\n",
       "  1       0.9127  0.9119  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  2       0.8968  0.8891  0.8636  0.8444  0.8539  0.7742  0.7743\n",
       "  3       0.8810  0.8717  0.8409  0.8222  0.8315  0.7395  0.7396\n",
       "  4       0.9048  0.9110  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.8889  0.8620  0.7727  0.8947  0.8293  0.7476  0.7520\n",
       "  6       0.9048  0.9111  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9286  0.9198  0.8889  0.9091  0.8989  0.8437  0.8438\n",
       "  8       0.9048  0.8864  0.8222  0.9024  0.8605  0.7884  0.7904\n",
       "  9       0.9444  0.9420  0.9333  0.9130  0.9231  0.8796  0.8797\n",
       "  Mean    0.9103  0.9030  0.8782  0.8709  0.8731  0.8038  0.8055\n",
       "  SD      0.0195  0.0237  0.0509  0.0405  0.0292  0.0435  0.0429,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.6667  0.0  0.1136  0.6250  0.1923  0.0951  0.1506\n",
       "  1       0.6508  0.0  1.0000  0.5000  0.6667  0.3762  0.4814\n",
       "  2       0.6270  0.0  1.0000  0.4835  0.6519  0.3421  0.4543\n",
       "  3       0.6270  0.0  1.0000  0.4835  0.6519  0.3421  0.4543\n",
       "  4       0.5873  0.0  1.0000  0.4583  0.6286  0.2872  0.4095\n",
       "  5       0.6746  0.0  0.0682  1.0000  0.1277  0.0870  0.2132\n",
       "  6       0.6429  0.0  0.0889  0.5000  0.1509  0.0483  0.0776\n",
       "  7       0.6349  0.0  1.0000  0.4945  0.6618  0.3521  0.4623\n",
       "  8       0.6667  0.0  0.0667  1.0000  0.1250  0.0841  0.2095\n",
       "  9       0.5873  0.0  1.0000  0.4639  0.6338  0.2849  0.4075\n",
       "  Mean    0.6365  0.0  0.6337  0.6009  0.4490  0.2299  0.3320\n",
       "  SD      0.0292  0.0  0.4487  0.2043  0.2458  0.1268  0.1441,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8413  0.0  0.7955  0.7609  0.7778  0.6544  0.6548\n",
       "  1       0.8651  0.0  0.8636  0.7755  0.8172  0.7108  0.7134\n",
       "  2       0.6825  0.0  0.4545  0.5556  0.5000  0.2708  0.2738\n",
       "  3       0.7619  0.0  0.5682  0.6944  0.6250  0.4531  0.4580\n",
       "  4       0.8333  0.0  0.7273  0.7805  0.7529  0.6274  0.6283\n",
       "  5       0.8571  0.0  0.7955  0.7955  0.7955  0.6857  0.6857\n",
       "  6       0.7937  0.0  0.9111  0.6508  0.7593  0.5873  0.6128\n",
       "  7       0.8810  0.0  0.8889  0.8000  0.8421  0.7470  0.7497\n",
       "  8       0.8254  0.0  0.6000  0.8710  0.7105  0.5915  0.6126\n",
       "  9       0.8968  0.0  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  Mean    0.8238  0.0  0.7471  0.7532  0.7437  0.6104  0.6166\n",
       "  SD      0.0604  0.0  0.1481  0.0901  0.1033  0.1432  0.1420,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9206  0.9771  0.8864  0.8864  0.8864  0.8254  0.8254\n",
       "  1       0.9127  0.9807  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  2       0.8968  0.9760  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  3       0.8889  0.9620  0.8864  0.8125  0.8478  0.7606  0.7624\n",
       "  4       0.9127  0.9778  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9206  0.9803  0.8864  0.8864  0.8864  0.8254  0.8254\n",
       "  6       0.9048  0.9811  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9286  0.9903  0.9111  0.8913  0.9011  0.8452  0.8453\n",
       "  8       0.9286  0.9818  0.9111  0.8913  0.9011  0.8452  0.8453\n",
       "  9       0.9603  0.9956  0.9333  0.9545  0.9438  0.9132  0.9133\n",
       "  Mean    0.9175  0.9803  0.9121  0.8636  0.8865  0.8218  0.8234\n",
       "  SD      0.0188  0.0084  0.0240  0.0430  0.0250  0.0399  0.0392,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7222  0.6813  0.5455  0.6154  0.5783  0.3723  0.3738\n",
       "  1       0.7381  0.6671  0.4318  0.7037  0.5352  0.3671  0.3883\n",
       "  2       0.6984  0.6261  0.3864  0.6071  0.4722  0.2754  0.2892\n",
       "  3       0.7063  0.6269  0.3636  0.6400  0.4638  0.2821  0.3035\n",
       "  4       0.6746  0.6183  0.4318  0.5429  0.4810  0.2485  0.2519\n",
       "  5       0.6429  0.5887  0.4091  0.4865  0.4444  0.1842  0.1857\n",
       "  6       0.6032  0.5185  0.2222  0.4000  0.2857  0.0411  0.0445\n",
       "  7       0.7063  0.6333  0.3778  0.6538  0.4789  0.2943  0.3157\n",
       "  8       0.7222  0.6506  0.4000  0.6923  0.5070  0.3324  0.3567\n",
       "  9       0.6349  0.5679  0.3333  0.4839  0.3947  0.1459  0.1511\n",
       "  Mean    0.6849  0.6179  0.3902  0.5826  0.4641  0.2543  0.2660\n",
       "  SD      0.0422  0.0460  0.0777  0.0952  0.0759  0.0989  0.1040,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8810  0.9600  0.8409  0.8222  0.8315  0.7395  0.7396\n",
       "  1       0.8968  0.9612  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.9206  0.9816  0.9091  0.8696  0.8889  0.8272  0.8277\n",
       "  3       0.9048  0.9683  0.8636  0.8636  0.8636  0.7905  0.7905\n",
       "  4       0.8968  0.9680  0.9545  0.7925  0.8660  0.7833  0.7922\n",
       "  5       0.9048  0.9830  0.8182  0.9000  0.8571  0.7860  0.7880\n",
       "  6       0.9048  0.9571  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9127  0.9844  0.8889  0.8696  0.8791  0.8108  0.8109\n",
       "  8       0.8968  0.9749  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  9       0.9841  0.9940  0.9556  1.0000  0.9773  0.9651  0.9657\n",
       "  Mean    0.9103  0.9732  0.8917  0.8619  0.8753  0.8054  0.8071\n",
       "  SD      0.0266  0.0116  0.0442  0.0545  0.0371  0.0576  0.0573,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8968  0.9726  0.8182  0.8780  0.8471  0.7694  0.7705\n",
       "  1       0.8968  0.9762  0.8636  0.8444  0.8539  0.7742  0.7743\n",
       "  2       0.9048  0.9734  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  3       0.8889  0.9623  0.8409  0.8409  0.8409  0.7555  0.7555\n",
       "  4       0.9048  0.9794  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9873  0.9545  0.8936  0.9231  0.8797  0.8808\n",
       "  6       0.9127  0.9811  0.9111  0.8542  0.8817  0.8127  0.8137\n",
       "  7       0.9444  0.9909  0.9556  0.8958  0.9247  0.8808  0.8819\n",
       "  8       0.9127  0.9781  0.9111  0.8542  0.8817  0.8127  0.8137\n",
       "  9       0.9603  0.9971  0.9333  0.9545  0.9438  0.9132  0.9133\n",
       "  Mean    0.9167  0.9798  0.9007  0.8684  0.8836  0.8188  0.8198\n",
       "  SD      0.0231  0.0095  0.0449  0.0366  0.0337  0.0511  0.0511,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8651  0.9521  0.7955  0.8140  0.8046  0.7016  0.7017\n",
       "  1       0.8968  0.9598  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.8571  0.9501  0.8182  0.7826  0.8000  0.6890  0.6894\n",
       "  3       0.8968  0.9728  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.8889  0.9471  0.9318  0.7885  0.8542  0.7654  0.7724\n",
       "  5       0.8651  0.9573  0.8864  0.7647  0.8211  0.7137  0.7187\n",
       "  6       0.8492  0.9561  0.8667  0.7500  0.8041  0.6826  0.6873\n",
       "  7       0.8968  0.9684  0.8889  0.8333  0.8602  0.7786  0.7796\n",
       "  8       0.9206  0.9781  0.8889  0.8889  0.8889  0.8272  0.8272\n",
       "  9       0.8968  0.9767  0.8889  0.8333  0.8602  0.7786  0.7796\n",
       "  Mean    0.8833  0.9618  0.8783  0.8089  0.8414  0.7494  0.7520\n",
       "  SD      0.0216  0.0108  0.0410  0.0382  0.0295  0.0463  0.0460,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9799  0.8182  0.9231  0.8675  0.8027  0.8060\n",
       "  1       0.8889  0.9712  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.9286  0.9830  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8968  0.9619  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  4       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9868  0.9091  0.9302  0.9195  0.8771  0.8773\n",
       "  6       0.9206  0.9864  0.9556  0.8431  0.8958  0.8321  0.8364\n",
       "  7       0.9524  0.9922  0.9333  0.9333  0.9333  0.8963  0.8963\n",
       "  8       0.9286  0.9857  0.8444  0.9500  0.8941  0.8405  0.8438\n",
       "  9       0.9683  0.9937  0.9778  0.9362  0.9565  0.9315  0.9321\n",
       "  Mean    0.9246  0.9809  0.9052  0.8867  0.8943  0.8358  0.8377\n",
       "  SD      0.0239  0.0100  0.0473  0.0518  0.0330  0.0515  0.0507,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8968  0.9759  0.8182  0.8780  0.8471  0.7694  0.7705\n",
       "  1       0.9206  0.9792  0.9091  0.8696  0.8889  0.8272  0.8277\n",
       "  2       0.9127  0.9814  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  3       0.8730  0.9601  0.8636  0.7917  0.8261  0.7264  0.7281\n",
       "  4       0.9048  0.9803  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9286  0.9875  0.8636  0.9268  0.8941  0.8403  0.8415\n",
       "  6       0.9048  0.9704  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9206  0.9819  0.9111  0.8723  0.8913  0.8289  0.8293\n",
       "  8       0.9127  0.9770  0.9111  0.8542  0.8817  0.8127  0.8137\n",
       "  9       0.9603  0.9964  0.9333  0.9545  0.9438  0.9132  0.9133\n",
       "  Mean    0.9135  0.9790  0.8984  0.8642  0.8799  0.8124  0.8140\n",
       "  SD      0.0214  0.0092  0.0360  0.0464  0.0293  0.0459  0.0454,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9789  0.8864  0.9070  0.8966  0.8420  0.8421\n",
       "  1       0.9127  0.9803  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  2       0.9286  0.9831  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8889  0.9687  0.8409  0.8409  0.8409  0.7555  0.7555\n",
       "  4       0.8889  0.9803  0.9318  0.7885  0.8542  0.7654  0.7724\n",
       "  5       0.9206  0.9856  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.9127  0.9775  0.9333  0.8400  0.8842  0.8145  0.8174\n",
       "  7       0.8968  0.9838  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  8       0.9048  0.9772  0.8667  0.8667  0.8667  0.7926  0.7926\n",
       "  9       0.9762  0.9967  0.9556  0.9773  0.9663  0.9479  0.9480\n",
       "  Mean    0.9159  0.9812  0.8963  0.8713  0.8828  0.8172  0.8184\n",
       "  SD      0.0244  0.0068  0.0353  0.0487  0.0331  0.0522  0.0516,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9048  0.9798  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  1       0.8968  0.9767  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.9048  0.9789  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  3       0.9048  0.9692  0.9091  0.8333  0.8696  0.7948  0.7967\n",
       "  4       0.9127  0.9828  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9286  0.9856  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  6       0.9048  0.9800  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9365  0.9904  0.9333  0.8936  0.9130  0.8631  0.8636\n",
       "  8       0.9206  0.9800  0.9111  0.8723  0.8913  0.8289  0.8293\n",
       "  9       0.9603  0.9973  0.9556  0.9348  0.9451  0.9140  0.9141\n",
       "  Mean    0.9175  0.9821  0.9142  0.8609  0.8865  0.8218  0.8230\n",
       "  SD      0.0185  0.0073  0.0227  0.0339  0.0253  0.0398  0.0393,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9799  0.8182  0.9231  0.8675  0.8027  0.8060\n",
       "  1       0.8889  0.9712  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.9286  0.9830  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8968  0.9619  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  4       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9868  0.9091  0.9302  0.9195  0.8771  0.8773\n",
       "  6       0.9206  0.9864  0.9556  0.8431  0.8958  0.8321  0.8364\n",
       "  7       0.9524  0.9922  0.9333  0.9333  0.9333  0.8963  0.8963\n",
       "  8       0.9286  0.9857  0.8444  0.9500  0.8941  0.8405  0.8438\n",
       "  9       0.9683  0.9937  0.9778  0.9362  0.9565  0.9315  0.9321\n",
       "  Mean    0.9246  0.9809  0.9052  0.8867  0.8943  0.8358  0.8377\n",
       "  SD      0.0239  0.0100  0.0473  0.0518  0.0330  0.0515  0.0507,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8968  0.9707  0.8636  0.8444  0.8539  0.7742  0.7743\n",
       "  1       0.8929  0.9689  0.8764  0.8298  0.8525  0.7684  0.7692\n",
       "  2       0.9167  0.9740  0.8989  0.8696  0.8840  0.8190  0.8193\n",
       "  3       0.9167  0.9857  0.9213  0.8542  0.8865  0.8208  0.8223\n",
       "  4       0.9444  0.9890  0.9213  0.9213  0.9213  0.8784  0.8784\n",
       "  Mean    0.9135  0.9777  0.8963  0.8639  0.8796  0.8122  0.8127\n",
       "  SD      0.0183  0.0082  0.0233  0.0315  0.0253  0.0397  0.0396,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9799  0.8182  0.9231  0.8675  0.8027  0.8060\n",
       "  1       0.8889  0.9712  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.9286  0.9830  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8968  0.9619  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  4       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9868  0.9091  0.9302  0.9195  0.8771  0.8773\n",
       "  6       0.9206  0.9864  0.9556  0.8431  0.8958  0.8321  0.8364\n",
       "  7       0.9524  0.9922  0.9333  0.9333  0.9333  0.8963  0.8963\n",
       "  8       0.9286  0.9857  0.8444  0.9500  0.8941  0.8405  0.8438\n",
       "  9       0.9683  0.9937  0.9778  0.9362  0.9565  0.9315  0.9321\n",
       "  Mean    0.9246  0.9809  0.9052  0.8867  0.8943  0.8358  0.8377\n",
       "  SD      0.0239  0.0100  0.0473  0.0518  0.0330  0.0515  0.0507,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9843  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9763  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.9803  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.9623  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.9814  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.9897  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.9809  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.9898  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9826  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.9945  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.9822  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0084  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9799  0.8182  0.9231  0.8675  0.8027  0.8060\n",
       "  1       0.8889  0.9712  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.9286  0.9830  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8968  0.9619  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  4       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9868  0.9091  0.9302  0.9195  0.8771  0.8773\n",
       "  6       0.9206  0.9864  0.9556  0.8431  0.8958  0.8321  0.8364\n",
       "  7       0.9524  0.9922  0.9333  0.9333  0.9333  0.8963  0.8963\n",
       "  8       0.9286  0.9857  0.8444  0.9500  0.8941  0.8405  0.8438\n",
       "  9       0.9683  0.9937  0.9778  0.9362  0.9565  0.9315  0.9321\n",
       "  Mean    0.9246  0.9809  0.9052  0.8867  0.8943  0.8358  0.8377\n",
       "  SD      0.0239  0.0100  0.0473  0.0518  0.0330  0.0515  0.0507,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9048  0.9798  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  1       0.8968  0.9767  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.9048  0.9789  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  3       0.9048  0.9692  0.9091  0.8333  0.8696  0.7948  0.7967\n",
       "  4       0.9127  0.9828  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9286  0.9856  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  6       0.9048  0.9800  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9365  0.9904  0.9333  0.8936  0.9130  0.8631  0.8636\n",
       "  8       0.9206  0.9800  0.9111  0.8723  0.8913  0.8289  0.8293\n",
       "  9       0.9603  0.9973  0.9556  0.9348  0.9451  0.9140  0.9141\n",
       "  Mean    0.9175  0.9821  0.9142  0.8609  0.8865  0.8218  0.8230\n",
       "  SD      0.0185  0.0073  0.0227  0.0339  0.0253  0.0398  0.0393,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9789  0.8864  0.9070  0.8966  0.8420  0.8421\n",
       "  1       0.9127  0.9803  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  2       0.9286  0.9831  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8889  0.9687  0.8409  0.8409  0.8409  0.7555  0.7555\n",
       "  4       0.8889  0.9803  0.9318  0.7885  0.8542  0.7654  0.7724\n",
       "  5       0.9206  0.9856  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.9127  0.9775  0.9333  0.8400  0.8842  0.8145  0.8174\n",
       "  7       0.8968  0.9838  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  8       0.9048  0.9772  0.8667  0.8667  0.8667  0.7926  0.7926\n",
       "  9       0.9762  0.9967  0.9556  0.9773  0.9663  0.9479  0.9480\n",
       "  Mean    0.9159  0.9812  0.8963  0.8713  0.8828  0.8172  0.8184\n",
       "  SD      0.0244  0.0068  0.0353  0.0487  0.0331  0.0522  0.0516,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9789  0.8864  0.9070  0.8966  0.8420  0.8421\n",
       "  1       0.9127  0.9803  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  2       0.9286  0.9831  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8889  0.9687  0.8409  0.8409  0.8409  0.7555  0.7555\n",
       "  4       0.8889  0.9803  0.9318  0.7885  0.8542  0.7654  0.7724\n",
       "  5       0.9206  0.9856  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.9127  0.9775  0.9333  0.8400  0.8842  0.8145  0.8174\n",
       "  7       0.8968  0.9838  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  8       0.9048  0.9772  0.8667  0.8667  0.8667  0.7926  0.7926\n",
       "  9       0.9762  0.9967  0.9556  0.9773  0.9663  0.9479  0.9480\n",
       "  Mean    0.9159  0.9812  0.8963  0.8713  0.8828  0.8172  0.8184\n",
       "  SD      0.0244  0.0068  0.0353  0.0487  0.0331  0.0522  0.0516,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7692  0.8611  0.7500  0.6000  0.6667  0.4935  0.5007\n",
       "  1       0.9231  1.0000  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  2       0.9231  0.9444  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  3       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  4       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      0.9167  1.0000  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  98      0.9167  0.9688  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9201  0.9818  0.9625  0.8518  0.8973  0.8331  0.8452\n",
       "  SD      0.0687  0.0306  0.0926  0.1261  0.0883  0.1428  0.1350\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7692  0.8889  0.5000  0.6667  0.5714  0.4179  0.4260\n",
       "  1       0.9231  0.9167  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  2       0.9231  0.9722  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  3       0.8462  1.0000  0.5000  1.0000  0.6667  0.5806  0.6396\n",
       "  4       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      0.9167  1.0000  0.7500  1.0000  0.8571  0.8000  0.8165\n",
       "  98      0.9167  0.9688  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9279  0.9835  0.9070  0.9038  0.8971  0.8419  0.8504\n",
       "  SD      0.0681  0.0264  0.1344  0.1177  0.1014  0.1511  0.1456\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9789  0.8864  0.9070  0.8966  0.8420  0.8421\n",
       "  1       0.9127  0.9803  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  2       0.9286  0.9831  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8889  0.9687  0.8409  0.8409  0.8409  0.7555  0.7555\n",
       "  4       0.8889  0.9803  0.9318  0.7885  0.8542  0.7654  0.7724\n",
       "  5       0.9206  0.9856  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.9127  0.9775  0.9333  0.8400  0.8842  0.8145  0.8174\n",
       "  7       0.8968  0.9838  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  8       0.9048  0.9772  0.8667  0.8667  0.8667  0.7926  0.7926\n",
       "  9       0.9762  0.9967  0.9556  0.9773  0.9663  0.9479  0.9480\n",
       "  Mean    0.9159  0.9812  0.8963  0.8713  0.8828  0.8172  0.8184\n",
       "  SD      0.0244  0.0068  0.0353  0.0487  0.0331  0.0522  0.0516,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7692  0.8611  0.7500  0.6000  0.6667  0.4935  0.5007\n",
       "  1       0.9231  1.0000  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  2       0.9231  0.9444  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  3       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  4       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      0.9167  1.0000  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  98      0.9167  0.9688  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9201  0.9818  0.9625  0.8518  0.8973  0.8331  0.8452\n",
       "  SD      0.0687  0.0306  0.0926  0.1261  0.0883  0.1428  0.1350\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7692  0.8889  0.5000  0.6667  0.5714  0.4179  0.4260\n",
       "  1       0.9231  0.9167  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  2       0.9231  0.9722  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  3       0.8462  1.0000  0.5000  1.0000  0.6667  0.5806  0.6396\n",
       "  4       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      0.9167  1.0000  0.7500  1.0000  0.8571  0.8000  0.8165\n",
       "  98      0.9167  0.9688  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9279  0.9835  0.9070  0.9038  0.8971  0.8419  0.8504\n",
       "  SD      0.0681  0.0264  0.1344  0.1177  0.1014  0.1511  0.1456\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9206  0.9771  0.8864  0.8864  0.8864  0.8254  0.8254\n",
       "  1       0.9127  0.9807  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  2       0.8968  0.9760  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  3       0.8889  0.9620  0.8864  0.8125  0.8478  0.7606  0.7624\n",
       "  4       0.9127  0.9778  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9206  0.9803  0.8864  0.8864  0.8864  0.8254  0.8254\n",
       "  6       0.9048  0.9811  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9286  0.9903  0.9111  0.8913  0.9011  0.8452  0.8453\n",
       "  8       0.9286  0.9818  0.9111  0.8913  0.9011  0.8452  0.8453\n",
       "  9       0.9603  0.9956  0.9333  0.9545  0.9438  0.9132  0.9133\n",
       "  Mean    0.9175  0.9803  0.9121  0.8636  0.8865  0.8218  0.8234\n",
       "  SD      0.0188  0.0084  0.0240  0.0430  0.0250  0.0399  0.0392,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7692  0.8472  0.7500  0.6000  0.6667  0.4935  0.5007\n",
       "  1       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  2       0.8462  0.9722  0.7500  0.7500  0.7500  0.6389  0.6389\n",
       "  3       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  4       0.9231  1.0000  0.7500  1.0000  0.8571  0.8060  0.8216\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  98      0.9167  1.0000  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9303  0.9680  0.9440  0.8859  0.9063  0.8511  0.8613\n",
       "  SD      0.0706  0.0477  0.1121  0.1299  0.0974  0.1512  0.1430\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8462  0.9028  0.7500  0.7500  0.7500  0.6389  0.6389\n",
       "  1       0.9231  1.0000  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  2       0.9231  0.9722  0.7500  1.0000  0.8571  0.8060  0.8216\n",
       "  3       0.9231  1.0000  0.7500  1.0000  0.8571  0.8060  0.8216\n",
       "  4       0.9231  1.0000  0.7500  1.0000  0.8571  0.8060  0.8216\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  98      0.9167  0.9688  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9169  0.9831  0.9095  0.8794  0.8858  0.8210  0.8304\n",
       "  SD      0.0769  0.0242  0.1254  0.1322  0.1046  0.1633  0.1567\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8968  0.9709  0.8636  0.8444  0.8539  0.7742  0.7743\n",
       "  1       0.9286  0.9778  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9365  0.9800  0.9545  0.8750  0.9130  0.8632  0.8652\n",
       "  3       0.9048  0.9665  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9781  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9365  0.9881  0.9091  0.9091  0.9091  0.8603  0.8603\n",
       "  6       0.9048  0.9830  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.9915  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9822  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9683  0.9953  1.0000  0.9184  0.9574  0.9322  0.9344\n",
       "  Mean    0.9238  0.9813  0.9480  0.8537  0.8976  0.8372  0.8411\n",
       "  SD      0.0198  0.0084  0.0381  0.0359  0.0267  0.0423  0.0417,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9773  0.8636  0.8837  0.8736  0.8069  0.8070\n",
       "  1       0.9048  0.9762  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  2       0.9206  0.9834  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  3       0.9127  0.9681  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  4       0.9048  0.9715  0.9545  0.8077  0.8750  0.7989  0.8062\n",
       "  5       0.9286  0.9878  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  6       0.9286  0.9846  0.9333  0.8750  0.9032  0.8467  0.8478\n",
       "  7       0.9365  0.9868  0.9333  0.8936  0.9130  0.8631  0.8636\n",
       "  8       0.8968  0.9824  0.8444  0.8636  0.8539  0.7742  0.7743\n",
       "  9       0.9365  0.9929  0.9111  0.9111  0.9111  0.8617  0.8617\n",
       "  Mean    0.9183  0.9811  0.9054  0.8700  0.8863  0.8226  0.8242\n",
       "  SD      0.0133  0.0073  0.0374  0.0326  0.0187  0.0288  0.0283,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9365  0.9709  0.9545  0.8750  0.9130  0.8632  0.8652\n",
       "  1       0.9286  0.9532  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  2       0.9127  0.9709  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  3       0.9286  0.9392  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  4       0.9048  0.9818  0.9545  0.8077  0.8750  0.7989  0.8062\n",
       "  5       0.9524  0.9818  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9365  0.9797  0.9556  0.8776  0.9149  0.8644  0.8664\n",
       "  7       0.9524  0.9807  1.0000  0.8824  0.9375  0.8993  0.9039\n",
       "  8       0.9206  0.9523  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9956  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9349  0.9706  0.9593  0.8698  0.9122  0.8607  0.8636\n",
       "  SD      0.0200  0.0164  0.0263  0.0319  0.0269  0.0427  0.0421,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9206  0.9771  0.8864  0.8864  0.8864  0.8254  0.8254\n",
       "  1       0.9127  0.9807  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  2       0.8968  0.9760  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  3       0.8889  0.9620  0.8864  0.8125  0.8478  0.7606  0.7624\n",
       "  4       0.9127  0.9778  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9206  0.9803  0.8864  0.8864  0.8864  0.8254  0.8254\n",
       "  6       0.9048  0.9811  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9286  0.9903  0.9111  0.8913  0.9011  0.8452  0.8453\n",
       "  8       0.9286  0.9818  0.9111  0.8913  0.9011  0.8452  0.8453\n",
       "  9       0.9603  0.9956  0.9333  0.9545  0.9438  0.9132  0.9133\n",
       "  Mean    0.9175  0.9803  0.9121  0.8636  0.8865  0.8218  0.8234\n",
       "  SD      0.0188  0.0084  0.0240  0.0430  0.0250  0.0399  0.0392,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9843  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9763  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.9803  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.9623  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.9814  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.9897  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.9809  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.9898  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9826  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.9945  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.9822  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0084  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9799  0.8182  0.9231  0.8675  0.8027  0.8060\n",
       "  1       0.8889  0.9712  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.9286  0.9830  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8968  0.9619  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  4       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9868  0.9091  0.9302  0.9195  0.8771  0.8773\n",
       "  6       0.9206  0.9864  0.9556  0.8431  0.8958  0.8321  0.8364\n",
       "  7       0.9524  0.9922  0.9333  0.9333  0.9333  0.8963  0.8963\n",
       "  8       0.9286  0.9857  0.8444  0.9500  0.8941  0.8405  0.8438\n",
       "  9       0.9683  0.9937  0.9778  0.9362  0.9565  0.9315  0.9321\n",
       "  Mean    0.9246  0.9809  0.9052  0.8867  0.8943  0.8358  0.8377\n",
       "  SD      0.0239  0.0100  0.0473  0.0518  0.0330  0.0515  0.0507,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9843  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9763  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.9803  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.9623  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.9814  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.9897  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.9809  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.9898  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9826  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.9945  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.9822  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0084  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9799  0.8182  0.9231  0.8675  0.8027  0.8060\n",
       "  1       0.8889  0.9712  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.9286  0.9830  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8968  0.9619  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  4       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9868  0.9091  0.9302  0.9195  0.8771  0.8773\n",
       "  6       0.9206  0.9864  0.9556  0.8431  0.8958  0.8321  0.8364\n",
       "  7       0.9524  0.9922  0.9333  0.9333  0.9333  0.8963  0.8963\n",
       "  8       0.9286  0.9857  0.8444  0.9500  0.8941  0.8405  0.8438\n",
       "  9       0.9683  0.9937  0.9778  0.9362  0.9565  0.9315  0.9321\n",
       "  Mean    0.9246  0.9809  0.9052  0.8867  0.8943  0.8358  0.8377\n",
       "  SD      0.0239  0.0100  0.0473  0.0518  0.0330  0.0515  0.0507,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9206  0.9828  0.9091  0.8696  0.8889  0.8272  0.8277\n",
       "  1       0.8968  0.9762  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.9048  0.9780  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  3       0.9127  0.9611  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  4       0.9127  0.9874  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9603  0.9843  0.9773  0.9149  0.9451  0.9141  0.9153\n",
       "  6       0.8810  0.9775  0.9333  0.7778  0.8485  0.7518  0.7603\n",
       "  7       0.9444  0.9855  0.9778  0.8800  0.9263  0.8819  0.8851\n",
       "  8       0.9127  0.9749  0.9111  0.8542  0.8817  0.8127  0.8137\n",
       "  9       0.9762  0.9947  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9222  0.9802  0.9345  0.8586  0.8945  0.8331  0.8355\n",
       "  SD      0.0279  0.0086  0.0386  0.0433  0.0371  0.0592  0.0584,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8968  0.9623  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  1       0.9127  0.9620  0.8409  0.9024  0.8706  0.8048  0.8060\n",
       "  2       0.8810  0.9748  0.8409  0.8222  0.8315  0.7395  0.7396\n",
       "  3       0.8730  0.9540  0.8409  0.8043  0.8222  0.7235  0.7240\n",
       "  4       0.8968  0.9678  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  5       0.9127  0.9770  0.8636  0.8837  0.8736  0.8069  0.8070\n",
       "  6       0.8968  0.9753  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  7       0.9206  0.9794  0.8667  0.9070  0.8864  0.8254  0.8259\n",
       "  8       0.9048  0.9761  0.8444  0.8837  0.8636  0.7905  0.7910\n",
       "  9       0.9444  0.9857  0.9333  0.9130  0.9231  0.8796  0.8797\n",
       "  Mean    0.9040  0.9715  0.8693  0.8610  0.8645  0.7902  0.7909\n",
       "  SD      0.0193  0.0091  0.0301  0.0393  0.0265  0.0415  0.0415,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9206  0.9828  0.9091  0.8696  0.8889  0.8272  0.8277\n",
       "  1       0.8968  0.9762  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.9048  0.9780  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  3       0.9127  0.9611  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  4       0.9127  0.9874  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9603  0.9843  0.9773  0.9149  0.9451  0.9141  0.9153\n",
       "  6       0.8810  0.9775  0.9333  0.7778  0.8485  0.7518  0.7603\n",
       "  7       0.9444  0.9855  0.9778  0.8800  0.9263  0.8819  0.8851\n",
       "  8       0.9127  0.9749  0.9111  0.8542  0.8817  0.8127  0.8137\n",
       "  9       0.9762  0.9947  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9222  0.9802  0.9345  0.8586  0.8945  0.8331  0.8355\n",
       "  SD      0.0279  0.0086  0.0386  0.0433  0.0371  0.0592  0.0584,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8571  0.9593  0.7955  0.7955  0.7955  0.6857  0.6857\n",
       "  1       0.9048  0.9739  0.8409  0.8810  0.8605  0.7882  0.7887\n",
       "  2       0.8968  0.9767  0.8182  0.8780  0.8471  0.7694  0.7705\n",
       "  3       0.8651  0.9537  0.8182  0.8000  0.8090  0.7047  0.7048\n",
       "  4       0.8810  0.9593  0.8864  0.7959  0.8387  0.7448  0.7475\n",
       "  5       0.9206  0.9881  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.8968  0.9772  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  7       0.9206  0.9794  0.8667  0.9070  0.8864  0.8254  0.8259\n",
       "  8       0.8810  0.9569  0.8000  0.8571  0.8276  0.7368  0.7379\n",
       "  9       0.9444  0.9874  0.9333  0.9130  0.9231  0.8796  0.8797\n",
       "  Mean    0.8968  0.9712  0.8489  0.8580  0.8529  0.7735  0.7741\n",
       "  SD      0.0256  0.0122  0.0407  0.0445  0.0363  0.0560  0.0559,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.0  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.0  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.0  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.0  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.0  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.0  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.0  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.0  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.0  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.0  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.0  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.0  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.0  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.0  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.0  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.0  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.0  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.0  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.0  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.0  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.0  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.0  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.0  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.0  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.0  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.0  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.0  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.0  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.0  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.0  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.0  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.0  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.0  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9868  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9774  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9286  0.9787  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  3       0.9048  0.9692  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9810  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9603  0.9886  0.9773  0.9149  0.9451  0.9141  0.9153\n",
       "  6       0.9206  0.9870  0.9778  0.8302  0.8980  0.8337  0.8412\n",
       "  7       0.9286  0.9905  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9968  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9310  0.9839  0.9662  0.8573  0.9082  0.8532  0.8575\n",
       "  SD      0.0204  0.0074  0.0208  0.0368  0.0267  0.0430  0.0418,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.0  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.0  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.0  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.0  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.0  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.0  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.0  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.0  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.0  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.0  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.0  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9866  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  1       0.9286  0.9794  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9206  0.9792  0.9318  0.8542  0.8913  0.8290  0.8309\n",
       "  3       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9807  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9683  0.9884  1.0000  0.9167  0.9565  0.9316  0.9338\n",
       "  6       0.9365  0.9872  0.9778  0.8627  0.9167  0.8657  0.8701\n",
       "  7       0.9286  0.9905  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9968  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9325  0.9840  0.9639  0.8618  0.9098  0.8562  0.8599\n",
       "  SD      0.0217  0.0074  0.0252  0.0356  0.0288  0.0460  0.0452,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9365  0.9866  0.9545  0.8750  0.9130  0.8632  0.8652\n",
       "  1       0.9206  0.9802  0.9545  0.8400  0.8936  0.8307  0.8351\n",
       "  2       0.9127  0.9820  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  3       0.9127  0.9676  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  4       0.9127  0.9830  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9524  0.9884  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9365  0.9878  0.9556  0.8776  0.9149  0.8644  0.8664\n",
       "  7       0.9286  0.9894  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9966  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9310  0.9844  0.9548  0.8641  0.9070  0.8523  0.8553\n",
       "  SD      0.0195  0.0072  0.0248  0.0320  0.0262  0.0415  0.0409,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9365  0.9866  0.9545  0.8750  0.9130  0.8632  0.8652\n",
       "  1       0.9206  0.9802  0.9545  0.8400  0.8936  0.8307  0.8351\n",
       "  2       0.9127  0.9820  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  3       0.9127  0.9676  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  4       0.9127  0.9830  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9524  0.9884  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9365  0.9878  0.9556  0.8776  0.9149  0.8644  0.8664\n",
       "  7       0.9286  0.9894  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9966  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9310  0.9844  0.9548  0.8641  0.9070  0.8523  0.8553\n",
       "  SD      0.0195  0.0072  0.0248  0.0320  0.0262  0.0415  0.0409,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9866  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  1       0.9286  0.9794  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9206  0.9792  0.9318  0.8542  0.8913  0.8290  0.8309\n",
       "  3       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9807  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9683  0.9884  1.0000  0.9167  0.9565  0.9316  0.9338\n",
       "  6       0.9365  0.9872  0.9778  0.8627  0.9167  0.8657  0.8701\n",
       "  7       0.9286  0.9905  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9968  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9325  0.9840  0.9639  0.8618  0.9098  0.8562  0.8599\n",
       "  SD      0.0217  0.0074  0.0252  0.0356  0.0288  0.0460  0.0452,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8895  0.9700  0.8939  0.8082  0.8489  0.7621  0.7645\n",
       "  1       0.9053  0.9766  0.9552  0.8101  0.8767  0.8006  0.8078\n",
       "  2       0.9211  0.9883  0.9552  0.8421  0.8951  0.8322  0.8365\n",
       "  3       0.9105  0.9736  0.8657  0.8788  0.8722  0.8034  0.8034\n",
       "  4       0.8895  0.9780  0.8806  0.8194  0.8489  0.7620  0.7632\n",
       "  5       0.9211  0.9794  0.9104  0.8714  0.8905  0.8288  0.8293\n",
       "  6       0.9048  0.9743  0.9091  0.8333  0.8696  0.7948  0.7967\n",
       "  7       0.9101  0.9741  0.9091  0.8451  0.8759  0.8055  0.8068\n",
       "  8       0.9206  0.9820  0.9545  0.8400  0.8936  0.8307  0.8351\n",
       "  9       0.8836  0.9783  0.9697  0.7619  0.8533  0.7591  0.7743\n",
       "  Mean    0.9056  0.9775  0.9204  0.8310  0.8725  0.7979  0.8018\n",
       "  SD      0.0132  0.0049  0.0341  0.0319  0.0167  0.0272  0.0261,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9000  0.9578  0.9242  0.8133  0.8652  0.7863  0.7903\n",
       "  1       0.8895  0.9683  0.9552  0.7805  0.8591  0.7697  0.7803\n",
       "  2       0.9105  0.9609  0.9403  0.8289  0.8811  0.8098  0.8140\n",
       "  3       0.9000  0.9513  0.8806  0.8429  0.8613  0.7832  0.7836\n",
       "  4       0.8842  0.9585  0.9403  0.7778  0.8514  0.7579  0.7671\n",
       "  5       0.9368  0.9706  0.9552  0.8767  0.9143  0.8644  0.8664\n",
       "  6       0.9101  0.9573  0.9242  0.8356  0.8777  0.8069  0.8094\n",
       "  7       0.8836  0.9481  0.9242  0.7821  0.8472  0.7543  0.7611\n",
       "  8       0.8836  0.9692  0.9545  0.7683  0.8514  0.7575  0.7696\n",
       "  9       0.8783  0.9543  0.9697  0.7529  0.8477  0.7490  0.7656\n",
       "  Mean    0.8977  0.9596  0.9369  0.8059  0.8656  0.7839  0.7907\n",
       "  SD      0.0170  0.0073  0.0239  0.0375  0.0197  0.0337  0.0305,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9868  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9774  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9286  0.9787  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  3       0.9048  0.9692  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9810  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9603  0.9886  0.9773  0.9149  0.9451  0.9141  0.9153\n",
       "  6       0.9206  0.9870  0.9778  0.8302  0.8980  0.8337  0.8412\n",
       "  7       0.9286  0.9905  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9968  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9310  0.9839  0.9662  0.8573  0.9082  0.8532  0.8575\n",
       "  SD      0.0204  0.0074  0.0208  0.0368  0.0267  0.0430  0.0418,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8947  0.9698  0.8939  0.8194  0.8551  0.7727  0.7745\n",
       "  1       0.9053  0.9757  0.9552  0.8101  0.8767  0.8006  0.8078\n",
       "  2       0.9158  0.9891  0.9552  0.8312  0.8889  0.8216  0.8268\n",
       "  3       0.9158  0.9737  0.8806  0.8806  0.8806  0.8156  0.8156\n",
       "  4       0.9000  0.9780  0.8806  0.8429  0.8613  0.7832  0.7836\n",
       "  5       0.9211  0.9793  0.9104  0.8714  0.8905  0.8288  0.8293\n",
       "  6       0.9048  0.9734  0.9091  0.8333  0.8696  0.7948  0.7967\n",
       "  7       0.9101  0.9745  0.9091  0.8451  0.8759  0.8055  0.8068\n",
       "  8       0.9259  0.9816  0.9697  0.8421  0.9014  0.8426  0.8479\n",
       "  9       0.8889  0.9777  0.9697  0.7711  0.8591  0.7693  0.7831\n",
       "  Mean    0.9082  0.9773  0.9234  0.8347  0.8759  0.8035  0.8072\n",
       "  SD      0.0111  0.0051  0.0338  0.0293  0.0142  0.0229  0.0222],\n",
       " [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                     random_state=456, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False),\n",
       "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "                       weights='uniform'),\n",
       "  GaussianNB(priors=None, var_smoothing=1e-09),\n",
       "  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=456, splitter='best'),\n",
       "  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
       "                l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "                max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
       "                power_t=0.5, random_state=456, shuffle=True, tol=0.001,\n",
       "                validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "  RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                  max_iter=None, normalize=False, random_state=456, solver='auto',\n",
       "                  tol=0.001),\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=456, verbose=0,\n",
       "                         warm_start=False),\n",
       "  QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "                                store_covariance=False, tol=0.0001),\n",
       "  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                     n_estimators=50, random_state=456),\n",
       "  GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=456, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False),\n",
       "  LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                             solver='svd', store_covariance=False, tol=0.0001),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "                objective='binary:logistic', random_state=456, reg_alpha=None,\n",
       "                reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                tree_method='auto', validate_parameters=None, verbosity=0),\n",
       "  LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=456, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "  <catboost.core.CatBoostClassifier at 0x22c9ea70ac0>,\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},\n",
       "                       criterion='entropy', max_depth=10, max_features=1.0,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0002, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=7,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  <catboost.core.CatBoostClassifier at 0x22c9d614c70>,\n",
       "  LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=456, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "  LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=456, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=11, max_features=1.0,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0002, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=170, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=456, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=11, max_features=1.0,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0002, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=170, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=456, verbose=0,\n",
       "                         warm_start=False),\n",
       "  RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
       "                         criterion='gini', max_depth=11, max_features=1.0,\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0002, min_impurity_split=None,\n",
       "                         min_samples_leaf=4, min_samples_split=10,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=170,\n",
       "                         n_jobs=-1, oob_score=False, random_state=456, verbose=0,\n",
       "                         warm_start=False),\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=456, verbose=0,\n",
       "                         warm_start=False),\n",
       "  BaggingClassifier(base_estimator=ExtraTreesClassifier(bootstrap=False,\n",
       "                                                        ccp_alpha=0.0,\n",
       "                                                        class_weight={},\n",
       "                                                        criterion='entropy',\n",
       "                                                        max_depth=10,\n",
       "                                                        max_features=1.0,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        max_samples=None,\n",
       "                                                        min_impurity_decrease=0.0002,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=7,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        n_estimators=80,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        oob_score=False,\n",
       "                                                        random_state=456,\n",
       "                                                        verbose=0,\n",
       "                                                        warm_start=False),\n",
       "                    bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                    max_samples=1.0, n_estimators=10, n_jobs=None,\n",
       "                    oob_score=False, random_state=456, verbose=0,\n",
       "                    warm_start=False),\n",
       "  AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                     base_estimator=ExtraTreesClassifier(bootstrap=False,\n",
       "                                                         ccp_alpha=0.0,\n",
       "                                                         class_weight={},\n",
       "                                                         criterion='entropy',\n",
       "                                                         max_depth=10,\n",
       "                                                         max_features=1.0,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         max_samples=None,\n",
       "                                                         min_impurity_decrease=0.0002,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=2,\n",
       "                                                         min_samples_split=7,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         n_estimators=80,\n",
       "                                                         n_jobs=-1,\n",
       "                                                         oob_score=False,\n",
       "                                                         random_state=456,\n",
       "                                                         verbose=0,\n",
       "                                                         warm_start=False),\n",
       "                     learning_rate=1.0, n_estimators=10, random_state=456),\n",
       "  RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
       "                         criterion='gini', max_depth=8, max_features=1.0,\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0, min_impurity_split=None,\n",
       "                         min_samples_leaf=3, min_samples_split=9,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=270,\n",
       "                         n_jobs=-1, oob_score=False, random_state=456, verbose=0,\n",
       "                         warm_start=False),\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=456, verbose=0,\n",
       "                         warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},\n",
       "                       criterion='entropy', max_depth=10, max_features=1.0,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0002, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=7,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},\n",
       "                       criterion='entropy', max_depth=10, max_features=1.0,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0002, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=7,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=456, verbose=0,\n",
       "                       warm_start=False),\n",
       "  BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=False,\n",
       "                                                          ccp_alpha=0.0,\n",
       "                                                          class_weight='balanced',\n",
       "                                                          criterion='gini',\n",
       "                                                          max_depth=8,\n",
       "                                                          max_features=1.0,\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          max_samples=None,\n",
       "                                                          min_impurity_decrease=0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=3,\n",
       "                                                          min_samples_split=9,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=270,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=456,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                    bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                    max_samples=1.0, n_estimators=10, n_jobs=None,\n",
       "                    oob_score=False, random_state=456, verbose=0,\n",
       "                    warm_start=False),\n",
       "  AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                     base_estimator=RandomForestClassifier(bootstrap=False,\n",
       "                                                           ccp_alpha=0.0,\n",
       "                                                           class_weight='balanced',\n",
       "                                                           criterion='gini',\n",
       "                                                           max_depth=8,\n",
       "                                                           max_features=1.0,\n",
       "                                                           max_leaf_nodes=None,\n",
       "                                                           max_samples=None,\n",
       "                                                           min_impurity_decrease=0,\n",
       "                                                           min_impurity_split=None,\n",
       "                                                           min_samples_leaf=3,\n",
       "                                                           min_samples_split=9,\n",
       "                                                           min_weight_fraction_leaf=0.0,\n",
       "                                                           n_estimators=270,\n",
       "                                                           n_jobs=-1,\n",
       "                                                           oob_score=False,\n",
       "                                                           random_state=456,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False),\n",
       "                     learning_rate=1.0, n_estimators=10, random_state=456),\n",
       "  BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=False,\n",
       "                                                          ccp_alpha=0.0,\n",
       "                                                          class_weight='balanced',\n",
       "                                                          criterion='gini',\n",
       "                                                          max_depth=8,\n",
       "                                                          max_features=1.0,\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          max_samples=None,\n",
       "                                                          min_impurity_decrease=0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=3,\n",
       "                                                          min_samples_split=9,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=270,\n",
       "                                                          n_jobs=-1,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=456,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                    bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                    max_samples=1.0, n_estimators=10, n_jobs=None,\n",
       "                    oob_score=False, random_state=456, verbose=0,\n",
       "                    warm_start=False),\n",
       "  AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                     base_estimator=RandomForestClassifier(bootstrap=False,\n",
       "                                                           ccp_alpha=0.0,\n",
       "                                                           class_weight='balanced',\n",
       "                                                           criterion='gini',\n",
       "                                                           max_depth=8,\n",
       "                                                           max_features=1.0,\n",
       "                                                           max_leaf_nodes=None,\n",
       "                                                           max_samples=None,\n",
       "                                                           min_impurity_decrease=0,\n",
       "                                                           min_impurity_split=None,\n",
       "                                                           min_samples_leaf=3,\n",
       "                                                           min_samples_split=9,\n",
       "                                                           min_weight_fraction_leaf=0.0,\n",
       "                                                           n_estimators=270,\n",
       "                                                           n_jobs=-1,\n",
       "                                                           oob_score=False,\n",
       "                                                           random_state=456,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False),\n",
       "                     learning_rate=1.0, n_estimators=10, random_state=456),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='hard', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weight_3=1, weights=[1, 1, 1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='hard', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weight_3=1, weights=[1, 1, 1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='hard', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weight_3=1, weights=[1, 1, 1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='soft', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weight_3=1, weights=[1, 1, 1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='hard', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weights=[1, 1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='soft', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weights=[1, 1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('rf',\n",
       "                                       RandomForestClassifier(bootstrap=False,\n",
       "                                                              ccp_alpha=0.0,\n",
       "                                                              class_weight='balanced',\n",
       "                                                              criterion='gini',\n",
       "                                                              max_depth=8,\n",
       "                                                              max_features=1.0,\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              max_samples=None,\n",
       "                                                              min_impurity_decrease=0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_samples_leaf=3,\n",
       "                                                              min_samples_split=9,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=270,\n",
       "                                                              n_jobs=-1,\n",
       "                                                              oob_s...\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='soft', weight_0=1, weight_1=1, weights=[1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                              max_features=1.0,\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              max_samples=None,\n",
       "                                                              min_impurity_decrease=0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_samples_leaf=3,\n",
       "                                                              min_samples_split=9,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=270,\n",
       "                                                              n_jobs=-1,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=456,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='soft', weight_0=1, weight_1=1, weights=[1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='soft', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weights=[1, 1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='soft', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weights=[1, 1, 1]),\n",
       "  RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
       "                         criterion='gini', max_depth=8, max_features=1.0,\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0, min_impurity_split=None,\n",
       "                         min_samples_leaf=3, min_samples_split=9,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=270,\n",
       "                         n_jobs=-1, oob_score=False, random_state=456, verbose=0,\n",
       "                         warm_start=False),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='soft', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weight_3=1, weights=[1, 1, 1, 1]),\n",
       "  TunableVotingClassifier(estimators=[('et',\n",
       "                                       ExtraTreesClassifier(bootstrap=False,\n",
       "                                                            ccp_alpha=0.0,\n",
       "                                                            class_weight={},\n",
       "                                                            criterion='entropy',\n",
       "                                                            max_depth=10,\n",
       "                                                            max_features=1.0,\n",
       "                                                            max_leaf_nodes=None,\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_sco...\n",
       "                                                            max_samples=None,\n",
       "                                                            min_impurity_decrease=0.0002,\n",
       "                                                            min_impurity_split=None,\n",
       "                                                            min_samples_leaf=2,\n",
       "                                                            min_samples_split=7,\n",
       "                                                            min_weight_fraction_leaf=0.0,\n",
       "                                                            n_estimators=80,\n",
       "                                                            n_jobs=-1,\n",
       "                                                            oob_score=False,\n",
       "                                                            random_state=456,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                          flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                          voting='soft', weight_0=1, weight_1=1, weight_2=1,\n",
       "                          weight_3=1, weights=[1, 1, 1, 1])],\n",
       " [('Setup Config',\n",
       "                                  Description                     Value\n",
       "   0                               session_id                       456\n",
       "   1                                   Target  It became a relationship\n",
       "   2                              Target Type                    Binary\n",
       "   3                            Label Encoded                0: 0, 1: 1\n",
       "   4                            Original Data                 (1896, 7)\n",
       "   5                           Missing Values                     False\n",
       "   6                         Numeric Features                         3\n",
       "   7                     Categorical Features                         3\n",
       "   8                         Ordinal Features                     False\n",
       "   9                High Cardinality Features                     False\n",
       "   10                 High Cardinality Method                      None\n",
       "   11                   Transformed Train Set                (1260, 69)\n",
       "   12                    Transformed Test Set                 (569, 69)\n",
       "   13                      Shuffle Train-Test                      True\n",
       "   14                     Stratify Train-Test                     False\n",
       "   15                          Fold Generator           StratifiedKFold\n",
       "   16                             Fold Number                        10\n",
       "   17                                CPU Jobs                        -1\n",
       "   18                                 Use GPU                     False\n",
       "   19                          Log Experiment                     False\n",
       "   20                         Experiment Name          clf-default-name\n",
       "   21                                     USI                      c354\n",
       "   22                         Imputation Type                    simple\n",
       "   23          Iterative Imputation Iteration                      None\n",
       "   24                         Numeric Imputer                      mean\n",
       "   25      Iterative Imputation Numeric Model                      None\n",
       "   26                     Categorical Imputer                  constant\n",
       "   27  Iterative Imputation Categorical Model                      None\n",
       "   28           Unknown Categoricals Handling            least_frequent\n",
       "   29                               Normalize                     False\n",
       "   30                        Normalize Method                      None\n",
       "   31                          Transformation                     False\n",
       "   32                   Transformation Method                      None\n",
       "   33                                     PCA                     False\n",
       "   34                              PCA Method                      None\n",
       "   35                          PCA Components                      None\n",
       "   36                     Ignore Low Variance                     False\n",
       "   37                     Combine Rare Levels                      True\n",
       "   38                    Rare Level Threshold                       0.1\n",
       "   39                         Numeric Binning                      True\n",
       "   40                         Remove Outliers                      True\n",
       "   41                      Outliers Threshold                      0.05\n",
       "   42                Remove Multicollinearity                      True\n",
       "   43             Multicollinearity Threshold                       0.9\n",
       "   44                              Clustering                     False\n",
       "   45                    Clustering Iteration                      None\n",
       "   46                     Polynomial Features                      True\n",
       "   47                       Polynomial Degree                         2\n",
       "   48                    Trignometry Features                      True\n",
       "   49                    Polynomial Threshold                       0.1\n",
       "   50                          Group Features                     False\n",
       "   51                       Feature Selection                      True\n",
       "   52            Features Selection Threshold                       0.8\n",
       "   53                     Feature Interaction                      True\n",
       "   54                           Feature Ratio                      True\n",
       "   55                   Interaction Threshold                      0.01\n",
       "   56                           Fix Imbalance                     False\n",
       "   57                    Fix Imbalance Method                     SMOTE),\n",
       "  ('X_training Set',\n",
       "         Count_3.0  Percentage_11.0  \\\n",
       "   1097        0.0              0.0   \n",
       "   1745        0.0              0.0   \n",
       "   1596        1.0              0.0   \n",
       "   265         0.0              0.0   \n",
       "   248         0.0              0.0   \n",
       "   ...         ...              ...   \n",
       "   495         0.0              0.0   \n",
       "   42          0.0              0.0   \n",
       "   601         0.0              0.0   \n",
       "   1707        0.0              0.0   \n",
       "   613         0.0              0.0   \n",
       "   \n",
       "         Segment Description_University of Notre Dame  Segment type_mobile  \\\n",
       "   1097                                           0.0                  0.0   \n",
       "   1745                                           0.0                  0.0   \n",
       "   1596                                           0.0                  0.0   \n",
       "   265                                            0.0                  0.0   \n",
       "   248                                            0.0                  0.0   \n",
       "   ...                                            ...                  ...   \n",
       "   495                                            0.0                  0.0   \n",
       "   42                                             0.0                  0.0   \n",
       "   601                                            0.0                  1.0   \n",
       "   1707                                           0.0                  0.0   \n",
       "   613                                            0.0                  1.0   \n",
       "   \n",
       "         Count_6.0  Count_11.0  Percentage_2.0  Count_4.0  \\\n",
       "   1097        0.0         0.0             0.0        0.0   \n",
       "   1745        0.0         0.0             0.0        0.0   \n",
       "   1596        0.0         0.0             0.0        0.0   \n",
       "   265         0.0         0.0             0.0        0.0   \n",
       "   248         0.0         0.0             0.0        0.0   \n",
       "   ...         ...         ...             ...        ...   \n",
       "   495         0.0         0.0             0.0        0.0   \n",
       "   42          0.0         0.0             0.0        0.0   \n",
       "   601         0.0         1.0             0.0        0.0   \n",
       "   1707        0.0         0.0             0.0        0.0   \n",
       "   613         0.0         0.0             1.0        0.0   \n",
       "   \n",
       "         Segment Description_Whatsgoodly University  Count_0.0  ...  \\\n",
       "   1097                                         0.0        0.0  ...   \n",
       "   1745                                         0.0        1.0  ...   \n",
       "   1596                                         0.0        0.0  ...   \n",
       "   265                                          0.0        1.0  ...   \n",
       "   248                                          0.0        1.0  ...   \n",
       "   ...                                          ...        ...  ...   \n",
       "   495                                          0.0        1.0  ...   \n",
       "   42                                           0.0        1.0  ...   \n",
       "   601                                          0.0        0.0  ...   \n",
       "   1707                                         0.0        0.0  ...   \n",
       "   613                                          0.0        0.0  ...   \n",
       "   \n",
       "         ID_multiply_Segment type_mobile  ID_multiply_Count_0.0  \\\n",
       "   1097                            0.000                0.00000   \n",
       "   1745                            0.000           293006.96875   \n",
       "   1596                            0.000                0.00000   \n",
       "   265                             0.000           293717.25000   \n",
       "   248                             0.000           293669.00000   \n",
       "   ...                               ...                    ...   \n",
       "   495                             0.000           293676.65625   \n",
       "   42                              0.000           292890.62500   \n",
       "   601                        292882.750                0.00000   \n",
       "   1707                            0.000                0.00000   \n",
       "   613                        292881.125                0.00000   \n",
       "   \n",
       "         sin(Percentage)_divide_Count_Power2  ID_divide_Count_Power2  \\\n",
       "   1097                         1.144707e-06                1.121155   \n",
       "   1745                         3.304094e-04              187.921280   \n",
       "   1596                         8.009666e-07                0.902167   \n",
       "   265                          0.000000e+00                0.000000   \n",
       "   248                          0.000000e+00                0.000000   \n",
       "   ...                                   ...                     ...   \n",
       "   495                          1.510835e-01           430553.437500   \n",
       "   42                           0.000000e+00                0.000000   \n",
       "   601                          1.364288e-07                0.087313   \n",
       "   1707                         3.472119e-07                0.227375   \n",
       "   613                          2.952058e-07                0.384994   \n",
       "   \n",
       "         Answer_No_multiply_Segment type_mobile  ID_multiply_Count_Power2  \\\n",
       "   1097                                     0.0              7.652064e+10   \n",
       "   1745                                     0.0              4.568566e+08   \n",
       "   1596                                     0.0              9.509206e+10   \n",
       "   265                                      0.0              0.000000e+00   \n",
       "   248                                      0.0              0.000000e+00   \n",
       "   ...                                      ...                       ...   \n",
       "   495                                      0.0              2.003142e+05   \n",
       "   42                                       0.0              0.000000e+00   \n",
       "   601                                      1.0              9.824440e+11   \n",
       "   1707                                     0.0              3.772910e+11   \n",
       "   613                                      1.0              2.228067e+11   \n",
       "   \n",
       "         Count_Power2_divide_tan(ID)  sin(Percentage)_multiply_ID  \\\n",
       "   1097                -6.050388e+04                 87593.671875   \n",
       "   1745                 3.334355e+04                150949.718750   \n",
       "   1596                 6.372099e+05                 76165.570312   \n",
       "   265                  0.000000e+00                     0.000000   \n",
       "   248                 -0.000000e+00                     0.000000   \n",
       "   ...                           ...                          ...   \n",
       "   495                  1.052553e+00                 30264.179688   \n",
       "   42                  -0.000000e+00                     0.000000   \n",
       "   601                  2.659296e+05                134033.687500   \n",
       "   1707                -1.530321e+06                130999.937500   \n",
       "   613                 -5.672445e+06                 65773.828125   \n",
       "   \n",
       "         ID_multiply_Answer_No  tan(ID)_multiply_Count_0.0  \n",
       "   1097           292901.90625                   -0.000000  \n",
       "   1745           293006.96875                    0.046762  \n",
       "   1596           292897.43750                    0.000000  \n",
       "   265                 0.00000                    0.340334  \n",
       "   248            293669.00000                   -1.025675  \n",
       "   ...                     ...                         ...  \n",
       "   495                 0.00000                    0.648035  \n",
       "   42             292890.62500                   -0.058160  \n",
       "   601            292882.75000                    0.000000  \n",
       "   1707           292893.12500                   -0.000000  \n",
       "   613            292881.12500                   -0.000000  \n",
       "   \n",
       "   [1260 rows x 69 columns]),\n",
       "  ('y_training Set',\n",
       "   1097    0\n",
       "   1745    1\n",
       "   1596    0\n",
       "   265     1\n",
       "   248     1\n",
       "          ..\n",
       "   495     1\n",
       "   42      0\n",
       "   601     0\n",
       "   1707    0\n",
       "   613     0\n",
       "   Name: It became a relationship, Length: 1260, dtype: int32),\n",
       "  ('X_test Set',\n",
       "         Count_3.0  Percentage_11.0  \\\n",
       "   687         0.0              0.0   \n",
       "   547         0.0              0.0   \n",
       "   1762        0.0              0.0   \n",
       "   1715        0.0              0.0   \n",
       "   683         0.0              1.0   \n",
       "   ...         ...              ...   \n",
       "   629         0.0              0.0   \n",
       "   1260        0.0              0.0   \n",
       "   970         0.0              0.0   \n",
       "   1864        0.0              0.0   \n",
       "   827         0.0              0.0   \n",
       "   \n",
       "         Segment Description_University of Notre Dame  Segment type_mobile  \\\n",
       "   687                                            0.0                  0.0   \n",
       "   547                                            0.0                  0.0   \n",
       "   1762                                           0.0                  0.0   \n",
       "   1715                                           0.0                  0.0   \n",
       "   683                                            0.0                  0.0   \n",
       "   ...                                            ...                  ...   \n",
       "   629                                            0.0                  0.0   \n",
       "   1260                                           0.0                  0.0   \n",
       "   970                                            0.0                  0.0   \n",
       "   1864                                           0.0                  0.0   \n",
       "   827                                            0.0                  0.0   \n",
       "   \n",
       "         Count_6.0  Count_11.0  Percentage_2.0  Count_4.0  \\\n",
       "   687         0.0         0.0             0.0        0.0   \n",
       "   547         0.0         0.0             0.0        0.0   \n",
       "   1762        0.0         0.0             0.0        0.0   \n",
       "   1715        0.0         0.0             0.0        0.0   \n",
       "   683         0.0         0.0             0.0        0.0   \n",
       "   ...         ...         ...             ...        ...   \n",
       "   629         0.0         0.0             0.0        0.0   \n",
       "   1260        0.0         0.0             1.0        0.0   \n",
       "   970         0.0         0.0             0.0        0.0   \n",
       "   1864        0.0         0.0             0.0        1.0   \n",
       "   827         0.0         0.0             0.0        0.0   \n",
       "   \n",
       "         Segment Description_Whatsgoodly University  Count_0.0  ...  \\\n",
       "   687                                          0.0        1.0  ...   \n",
       "   547                                          0.0        1.0  ...   \n",
       "   1762                                         0.0        1.0  ...   \n",
       "   1715                                         0.0        0.0  ...   \n",
       "   683                                          0.0        1.0  ...   \n",
       "   ...                                          ...        ...  ...   \n",
       "   629                                          0.0        1.0  ...   \n",
       "   1260                                         0.0        0.0  ...   \n",
       "   970                                          0.0        1.0  ...   \n",
       "   1864                                         0.0        0.0  ...   \n",
       "   827                                          0.0        1.0  ...   \n",
       "   \n",
       "         ID_multiply_Segment type_mobile  ID_multiply_Count_0.0  \\\n",
       "   687                               0.0           292890.84375   \n",
       "   547                               0.0           292888.06250   \n",
       "   1762                              0.0           292890.21875   \n",
       "   1715                              0.0                0.00000   \n",
       "   683                               0.0           293237.00000   \n",
       "   ...                               ...                    ...   \n",
       "   629                               0.0           292888.84375   \n",
       "   1260                              0.0                0.00000   \n",
       "   970                               0.0           292890.56250   \n",
       "   1864                              0.0                0.00000   \n",
       "   827                               0.0           293775.00000   \n",
       "   \n",
       "         sin(Percentage)_divide_Count_Power2  ID_divide_Count_Power2  \\\n",
       "   687                          0.000000e+00                0.000000   \n",
       "   547                          0.000000e+00                0.000000   \n",
       "   1762                         0.000000e+00                0.000000   \n",
       "   1715                         5.628085e-07                0.392062   \n",
       "   683                          8.414710e-01           293237.000000   \n",
       "   ...                                   ...                     ...   \n",
       "   629                          0.000000e+00                0.000000   \n",
       "   1260                         1.058827e-06                1.210664   \n",
       "   970                          0.000000e+00                0.000000   \n",
       "   1864                         7.507060e-07                0.503461   \n",
       "   827                          0.000000e+00                0.000000   \n",
       "   \n",
       "         Answer_No_multiply_Segment type_mobile  ID_multiply_Count_Power2  \\\n",
       "   687                                      0.0              0.000000e+00   \n",
       "   547                                      0.0              0.000000e+00   \n",
       "   1762                                     0.0              0.000000e+00   \n",
       "   1715                                     0.0              2.188145e+11   \n",
       "   683                                      0.0              2.932370e+05   \n",
       "   ...                                      ...                       ...   \n",
       "   629                                      0.0              0.000000e+00   \n",
       "   1260                                     0.0              7.086109e+10   \n",
       "   970                                      0.0              0.000000e+00   \n",
       "   1864                                     0.0              1.704018e+11   \n",
       "   827                                      0.0              0.000000e+00   \n",
       "   \n",
       "         Count_Power2_divide_tan(ID)  sin(Percentage)_multiply_ID  \\\n",
       "   687                  0.000000e+00                     0.000000   \n",
       "   547                  0.000000e+00                     0.000000   \n",
       "   1762                -0.000000e+00                     0.000000   \n",
       "   1715                 1.466272e+06                123150.656250   \n",
       "   683                  1.091420e+00                246750.421875   \n",
       "   ...                           ...                          ...   \n",
       "   629                  0.000000e+00                     0.000000   \n",
       "   1260                 4.094108e+05                 75029.617188   \n",
       "   970                 -0.000000e+00                     0.000000   \n",
       "   1864                 2.125835e+06                127921.664062   \n",
       "   827                  0.000000e+00                     0.000000   \n",
       "   \n",
       "         ID_multiply_Answer_No  tan(ID)_multiply_Count_0.0  \n",
       "   687            292890.84375                    0.162052  \n",
       "   547            292888.06250                    0.573888  \n",
       "   1762           292890.21875                   -0.500871  \n",
       "   1715           292897.43750                    0.000000  \n",
       "   683            293237.00000                    0.916237  \n",
       "   ...                     ...                         ...  \n",
       "   629            292888.84375                    3.633782  \n",
       "   1260           292897.50000                    0.000000  \n",
       "   970            292890.56250                   -0.121182  \n",
       "   1864           292900.37500                    0.000000  \n",
       "   827                 0.00000                   24.125525  \n",
       "   \n",
       "   [569 rows x 69 columns]),\n",
       "  ('y_test Set',\n",
       "   687     0\n",
       "   547     0\n",
       "   1762    0\n",
       "   1715    1\n",
       "   683     1\n",
       "          ..\n",
       "   629     0\n",
       "   1260    0\n",
       "   970     0\n",
       "   1864    0\n",
       "   827     0\n",
       "   Name: It became a relationship, Length: 569, dtype: int64),\n",
       "  ('Transformation Pipeline',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('dtypes',\n",
       "                    DataTypes_Auto_infer(categorical_features=[],\n",
       "                                         display_types=True, features_todrop=[],\n",
       "                                         id_columns=[],\n",
       "                                         ml_usecase='classification',\n",
       "                                         numerical_features=[],\n",
       "                                         target='It became a relationship',\n",
       "                                         time_features=[])),\n",
       "                   ('imputer',\n",
       "                    Simple_Imputer(categorical_strategy='not_available',\n",
       "                                   fill_value_categorical=None,\n",
       "                                   fill_value_numerical=Non...\n",
       "                    Fix_multicollinearity(correlation_with_target_preference=None,\n",
       "                                          correlation_with_target_threshold=0.0,\n",
       "                                          target_variable='It became a '\n",
       "                                                          'relationship',\n",
       "                                          threshold=0.9)),\n",
       "                   ('dfs',\n",
       "                    DFS_Classic(interactions=['multiply', 'divide'],\n",
       "                                ml_usecase='classification', random_state=456,\n",
       "                                subclass='binary',\n",
       "                                target='It became a relationship',\n",
       "                                top_features_to_pick_percentage=None)),\n",
       "                   ('pca', 'passthrough')],\n",
       "            verbose=False))],\n",
       " 'lightgbm',\n",
       " 456,\n",
       " Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=True, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=[],\n",
       "                                       target='It became a relationship',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='not_available',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_numerical=Non...\n",
       "                  Fix_multicollinearity(correlation_with_target_preference=None,\n",
       "                                        correlation_with_target_threshold=0.0,\n",
       "                                        target_variable='It became a '\n",
       "                                                        'relationship',\n",
       "                                        threshold=0.9)),\n",
       "                 ('dfs',\n",
       "                  DFS_Classic(interactions=['multiply', 'divide'],\n",
       "                              ml_usecase='classification', random_state=456,\n",
       "                              subclass='binary',\n",
       "                              target='It became a relationship',\n",
       "                              top_features_to_pick_percentage=None)),\n",
       "                 ('pca', 'passthrough')],\n",
       "          verbose=False),\n",
       " StratifiedKFold(n_splits=10, random_state=456, shuffle=False),\n",
       " {'USI',\n",
       "  'X',\n",
       "  'X_test',\n",
       "  'X_train',\n",
       "  '_all_metrics',\n",
       "  '_all_models',\n",
       "  '_all_models_internal',\n",
       "  '_available_plots',\n",
       "  '_gpu_n_jobs_param',\n",
       "  '_internal_pipeline',\n",
       "  '_ml_usecase',\n",
       "  'create_model_container',\n",
       "  'data_before_preprocess',\n",
       "  'display_container',\n",
       "  'exp_name_log',\n",
       "  'experiment__',\n",
       "  'fix_imbalance_method_param',\n",
       "  'fix_imbalance_param',\n",
       "  'fold_generator',\n",
       "  'fold_groups_param',\n",
       "  'fold_param',\n",
       "  'fold_shuffle_param',\n",
       "  'gpu_param',\n",
       "  'html_param',\n",
       "  'imputation_classifier',\n",
       "  'imputation_regressor',\n",
       "  'iterative_imputation_iters_param',\n",
       "  'log_plots_param',\n",
       "  'logging_param',\n",
       "  'master_model_container',\n",
       "  'n_jobs_param',\n",
       "  'prep_pipe',\n",
       "  'pycaret_globals',\n",
       "  'seed',\n",
       "  'stratify_param',\n",
       "  'target_param',\n",
       "  'transform_target_method_param',\n",
       "  'transform_target_param',\n",
       "  'y',\n",
       "  'y_test',\n",
       "  'y_train'},\n",
       " False,\n",
       " 'clf-default-name',\n",
       " 5,\n",
       " False,\n",
       " False,\n",
       " None,\n",
       "       Count_3.0  Percentage_11.0  \\\n",
       " 0           0.0              0.0   \n",
       " 1           0.0              0.0   \n",
       " 2           0.0              0.0   \n",
       " 3           0.0              0.0   \n",
       " 4           0.0              0.0   \n",
       " ...         ...              ...   \n",
       " 1891        0.0              0.0   \n",
       " 1892        0.0              0.0   \n",
       " 1893        0.0              0.0   \n",
       " 1894        0.0              0.0   \n",
       " 1895        0.0              0.0   \n",
       " \n",
       "       Segment Description_University of Notre Dame  Segment type_mobile  \\\n",
       " 0                                              0.0                  0.0   \n",
       " 1                                              0.0                  0.0   \n",
       " 2                                              0.0                  0.0   \n",
       " 3                                              0.0                  0.0   \n",
       " 4                                              0.0                  0.0   \n",
       " ...                                            ...                  ...   \n",
       " 1891                                           0.0                  0.0   \n",
       " 1892                                           0.0                  1.0   \n",
       " 1893                                           0.0                  0.0   \n",
       " 1894                                           0.0                  0.0   \n",
       " 1895                                           0.0                  0.0   \n",
       " \n",
       "       Count_6.0  Count_11.0  Percentage_2.0  Count_4.0  \\\n",
       " 0           0.0         0.0             0.0        0.0   \n",
       " 1           0.0         0.0             0.0        0.0   \n",
       " 2           0.0         0.0             1.0        0.0   \n",
       " 3           0.0         0.0             0.0        0.0   \n",
       " 4           0.0         0.0             1.0        0.0   \n",
       " ...         ...         ...             ...        ...   \n",
       " 1891        0.0         0.0             0.0        0.0   \n",
       " 1892        0.0         0.0             0.0        0.0   \n",
       " 1893        0.0         0.0             0.0        1.0   \n",
       " 1894        0.0         0.0             0.0        0.0   \n",
       " 1895        0.0         0.0             0.0        0.0   \n",
       " \n",
       "       Segment Description_Whatsgoodly University  Count_0.0  ...  \\\n",
       " 0                                            0.0        1.0  ...   \n",
       " 1                                            0.0        1.0  ...   \n",
       " 2                                            0.0        0.0  ...   \n",
       " 3                                            0.0        1.0  ...   \n",
       " 4                                            0.0        0.0  ...   \n",
       " ...                                          ...        ...  ...   \n",
       " 1891                                         0.0        1.0  ...   \n",
       " 1892                                         0.0        0.0  ...   \n",
       " 1893                                         0.0        0.0  ...   \n",
       " 1894                                         0.0        0.0  ...   \n",
       " 1895                                         0.0        1.0  ...   \n",
       " \n",
       "       ID_multiply_Segment type_mobile  ID_multiply_Count_0.0  \\\n",
       " 0                              0.0000           292890.90625   \n",
       " 1                              0.0000           292888.00000   \n",
       " 2                              0.0000                0.00000   \n",
       " 3                              0.0000           292887.12500   \n",
       " 4                              0.0000                0.00000   \n",
       " ...                               ...                    ...   \n",
       " 1891                           0.0000           292887.56250   \n",
       " 1892                      292881.6875                0.00000   \n",
       " 1893                           0.0000                0.00000   \n",
       " 1894                           0.0000                0.00000   \n",
       " 1895                           0.0000           292890.28125   \n",
       " \n",
       "       sin(Percentage)_divide_Count_Power2  ID_divide_Count_Power2  \\\n",
       " 0                            0.000000e+00                0.000000   \n",
       " 1                            0.000000e+00                0.000000   \n",
       " 2                            8.963794e-07                1.175459   \n",
       " 3                            0.000000e+00                0.000000   \n",
       " 4                            1.009242e-06                1.409034   \n",
       " ...                                   ...                     ...   \n",
       " 1891                         0.000000e+00                0.000000   \n",
       " 1892                         2.122762e-07                0.202313   \n",
       " 1893                         7.210842e-07                0.450446   \n",
       " 1894                         3.554738e-07                0.221651   \n",
       " 1895                         0.000000e+00                0.000000   \n",
       " \n",
       "       Answer_No_multiply_Segment type_mobile  ID_multiply_Count_Power2  \\\n",
       " 0                                        0.0              0.000000e+00   \n",
       " 1                                        0.0              0.000000e+00   \n",
       " 2                                        0.0              7.298168e+10   \n",
       " 3                                        0.0              0.000000e+00   \n",
       " 4                                        0.0              6.088336e+10   \n",
       " ...                                      ...                       ...   \n",
       " 1891                                     0.0              0.000000e+00   \n",
       " 1892                                     1.0              4.239952e+11   \n",
       " 1893                                     0.0              1.904578e+11   \n",
       " 1894                                     0.0              3.870352e+11   \n",
       " 1895                                     0.0              0.000000e+00   \n",
       " \n",
       "       Count_Power2_divide_tan(ID)  sin(Percentage)_multiply_ID  \\\n",
       " 0                    0.000000e+00                     0.000000   \n",
       " 1                    0.000000e+00                     0.000000   \n",
       " 2                    1.027946e+06                 65419.265625   \n",
       " 3                   -0.000000e+00                     0.000000   \n",
       " 4                   -1.222410e+06                 61446.054688   \n",
       " ...                           ...                          ...   \n",
       " 1891                 0.000000e+00                     0.000000   \n",
       " 1892                 3.163377e+06                 90004.078125   \n",
       " 1893                 7.180612e+05                137336.156250   \n",
       " 1894                 2.624169e+07                137580.875000   \n",
       " 1895                -0.000000e+00                     0.000000   \n",
       " \n",
       "       ID_multiply_Answer_No  tan(ID)_multiply_Count_0.0  \n",
       " 0              292890.90625                    0.226935  \n",
       " 1              292888.00000                    0.493580  \n",
       " 2              292894.06250                    0.000000  \n",
       " 3              292887.12500                   -0.442383  \n",
       " 4              292893.65625                   -0.000000  \n",
       " ...                     ...                         ...  \n",
       " 1891           292887.56250                    0.021002  \n",
       " 1892           292881.68750                    0.000000  \n",
       " 1893           292900.84375                    0.000000  \n",
       " 1894           292893.87500                    0.000000  \n",
       " 1895           292890.28125                   -0.424969  \n",
       " \n",
       " [1896 rows x 69 columns],\n",
       " [                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "  et                 Extra Trees Classifier    0.9246  0.9809  0.9052  0.8867   \n",
       "  rf               Random Forest Classifier    0.9175  0.9803  0.9121  0.8636   \n",
       "  catboost              CatBoost Classifier    0.9175  0.9821  0.9142  0.8609   \n",
       "  gbc          Gradient Boosting Classifier    0.9167  0.9798  0.9007  0.8684   \n",
       "  lightgbm  Light Gradient Boosting Machine    0.9159  0.9812  0.8963  0.8713   \n",
       "  xgboost         Extreme Gradient Boosting    0.9135  0.9790  0.8984  0.8642   \n",
       "  ada                  Ada Boost Classifier    0.9103  0.9732  0.8917  0.8619   \n",
       "  dt               Decision Tree Classifier    0.9103  0.9030  0.8782  0.8709   \n",
       "  lda          Linear Discriminant Analysis    0.8833  0.9618  0.8783  0.8089   \n",
       "  knn                K Neighbors Classifier    0.8698  0.9339  0.8536  0.7965   \n",
       "  ridge                    Ridge Classifier    0.8238  0.0000  0.7471  0.7532   \n",
       "  qda       Quadratic Discriminant Analysis    0.6849  0.6179  0.3902  0.5826   \n",
       "  svm                   SVM - Linear Kernel    0.6365  0.0000  0.6337  0.6009   \n",
       "  nb                            Naive Bayes    0.6563  0.7715  0.0338  0.6833   \n",
       "  lr                    Logistic Regression    0.6508  0.3332  0.0090  0.3000   \n",
       "  \n",
       "                F1   Kappa     MCC  TT (Sec)  \n",
       "  et        0.8943  0.8358  0.8377     0.157  \n",
       "  rf        0.8865  0.8218  0.8234     0.188  \n",
       "  catboost  0.8865  0.8218  0.8230     6.555  \n",
       "  gbc       0.8836  0.8188  0.8198     0.283  \n",
       "  lightgbm  0.8828  0.8172  0.8184     0.103  \n",
       "  xgboost   0.8799  0.8124  0.8140     0.319  \n",
       "  ada       0.8753  0.8054  0.8071     0.109  \n",
       "  dt        0.8731  0.8038  0.8055     0.018  \n",
       "  lda       0.8414  0.7494  0.7520     0.016  \n",
       "  knn       0.8226  0.7202  0.7229     0.027  \n",
       "  ridge     0.7437  0.6104  0.6166     0.017  \n",
       "  qda       0.4641  0.2543  0.2660     0.022  \n",
       "  svm       0.4490  0.2299  0.3320     0.020  \n",
       "  nb        0.0639  0.0368  0.1060     0.013  \n",
       "  lr        0.0175  0.0116  0.0415     0.014  ,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9799  0.8182  0.9231  0.8675  0.8027  0.8060\n",
       "  1       0.8889  0.9712  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.9286  0.9830  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8968  0.9619  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  4       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9868  0.9091  0.9302  0.9195  0.8771  0.8773\n",
       "  6       0.9206  0.9864  0.9556  0.8431  0.8958  0.8321  0.8364\n",
       "  7       0.9524  0.9922  0.9333  0.9333  0.9333  0.8963  0.8963\n",
       "  8       0.9286  0.9857  0.8444  0.9500  0.8941  0.8405  0.8438\n",
       "  9       0.9683  0.9937  0.9778  0.9362  0.9565  0.9315  0.9321\n",
       "  Mean    0.9246  0.9809  0.9052  0.8867  0.8943  0.8358  0.8377\n",
       "  SD      0.0239  0.0100  0.0473  0.0518  0.0330  0.0515  0.0507,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8968  0.9707  0.8636  0.8444  0.8539  0.7742  0.7743\n",
       "  1       0.8929  0.9689  0.8764  0.8298  0.8525  0.7684  0.7692\n",
       "  2       0.9167  0.9740  0.8989  0.8696  0.8840  0.8190  0.8193\n",
       "  3       0.9167  0.9857  0.9213  0.8542  0.8865  0.8208  0.8223\n",
       "  4       0.9444  0.9890  0.9213  0.9213  0.9213  0.8784  0.8784\n",
       "  Mean    0.9135  0.9777  0.8963  0.8639  0.8796  0.8122  0.8127\n",
       "  SD      0.0183  0.0082  0.0233  0.0315  0.0253  0.0397  0.0396,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9799  0.8182  0.9231  0.8675  0.8027  0.8060\n",
       "  1       0.8889  0.9712  0.8636  0.8261  0.8444  0.7581  0.7585\n",
       "  2       0.9286  0.9830  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8968  0.9619  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  4       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  5       0.9444  0.9868  0.9091  0.9302  0.9195  0.8771  0.8773\n",
       "  6       0.9206  0.9864  0.9556  0.8431  0.8958  0.8321  0.8364\n",
       "  7       0.9524  0.9922  0.9333  0.9333  0.9333  0.8963  0.8963\n",
       "  8       0.9286  0.9857  0.8444  0.9500  0.8941  0.8405  0.8438\n",
       "  9       0.9683  0.9937  0.9778  0.9362  0.9565  0.9315  0.9321\n",
       "  Mean    0.9246  0.9809  0.9052  0.8867  0.8943  0.8358  0.8377\n",
       "  SD      0.0239  0.0100  0.0473  0.0518  0.0330  0.0515  0.0507,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9843  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9763  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.9803  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.9623  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.9814  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.9897  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.9809  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.9898  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9826  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.9945  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.9822  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0084  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9048  0.9798  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  1       0.8968  0.9767  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.9048  0.9789  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  3       0.9048  0.9692  0.9091  0.8333  0.8696  0.7948  0.7967\n",
       "  4       0.9127  0.9828  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9286  0.9856  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  6       0.9048  0.9800  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9365  0.9904  0.9333  0.8936  0.9130  0.8631  0.8636\n",
       "  8       0.9206  0.9800  0.9111  0.8723  0.8913  0.8289  0.8293\n",
       "  9       0.9603  0.9973  0.9556  0.9348  0.9451  0.9140  0.9141\n",
       "  Mean    0.9175  0.9821  0.9142  0.8609  0.8865  0.8218  0.8230\n",
       "  SD      0.0185  0.0073  0.0227  0.0339  0.0253  0.0398  0.0393,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9789  0.8864  0.9070  0.8966  0.8420  0.8421\n",
       "  1       0.9127  0.9803  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  2       0.9286  0.9831  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8889  0.9687  0.8409  0.8409  0.8409  0.7555  0.7555\n",
       "  4       0.8889  0.9803  0.9318  0.7885  0.8542  0.7654  0.7724\n",
       "  5       0.9206  0.9856  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.9127  0.9775  0.9333  0.8400  0.8842  0.8145  0.8174\n",
       "  7       0.8968  0.9838  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  8       0.9048  0.9772  0.8667  0.8667  0.8667  0.7926  0.7926\n",
       "  9       0.9762  0.9967  0.9556  0.9773  0.9663  0.9479  0.9480\n",
       "  Mean    0.9159  0.9812  0.8963  0.8713  0.8828  0.8172  0.8184\n",
       "  SD      0.0244  0.0068  0.0353  0.0487  0.0331  0.0522  0.0516,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9789  0.8864  0.9070  0.8966  0.8420  0.8421\n",
       "  1       0.9127  0.9803  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  2       0.9286  0.9831  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8889  0.9687  0.8409  0.8409  0.8409  0.7555  0.7555\n",
       "  4       0.8889  0.9803  0.9318  0.7885  0.8542  0.7654  0.7724\n",
       "  5       0.9206  0.9856  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.9127  0.9775  0.9333  0.8400  0.8842  0.8145  0.8174\n",
       "  7       0.8968  0.9838  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  8       0.9048  0.9772  0.8667  0.8667  0.8667  0.7926  0.7926\n",
       "  9       0.9762  0.9967  0.9556  0.9773  0.9663  0.9479  0.9480\n",
       "  Mean    0.9159  0.9812  0.8963  0.8713  0.8828  0.8172  0.8184\n",
       "  SD      0.0244  0.0068  0.0353  0.0487  0.0331  0.0522  0.0516,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7692  0.8611  0.7500  0.6000  0.6667  0.4935  0.5007\n",
       "  1       0.9231  1.0000  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  2       0.9231  0.9444  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  3       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  4       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      0.9167  1.0000  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  98      0.9167  0.9688  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9201  0.9818  0.9625  0.8518  0.8973  0.8331  0.8452\n",
       "  SD      0.0687  0.0306  0.0926  0.1261  0.0883  0.1428  0.1350\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9789  0.8864  0.9070  0.8966  0.8420  0.8421\n",
       "  1       0.9127  0.9803  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  2       0.9286  0.9831  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  3       0.8889  0.9687  0.8409  0.8409  0.8409  0.7555  0.7555\n",
       "  4       0.8889  0.9803  0.9318  0.7885  0.8542  0.7654  0.7724\n",
       "  5       0.9206  0.9856  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.9127  0.9775  0.9333  0.8400  0.8842  0.8145  0.8174\n",
       "  7       0.8968  0.9838  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  8       0.9048  0.9772  0.8667  0.8667  0.8667  0.7926  0.7926\n",
       "  9       0.9762  0.9967  0.9556  0.9773  0.9663  0.9479  0.9480\n",
       "  Mean    0.9159  0.9812  0.8963  0.8713  0.8828  0.8172  0.8184\n",
       "  SD      0.0244  0.0068  0.0353  0.0487  0.0331  0.0522  0.0516,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7692  0.8611  0.7500  0.6000  0.6667  0.4935  0.5007\n",
       "  1       0.9231  1.0000  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  2       0.9231  0.9444  1.0000  0.8000  0.8889  0.8312  0.8433\n",
       "  3       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  4       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      0.9167  1.0000  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  98      0.9167  0.9688  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9201  0.9818  0.9625  0.8518  0.8973  0.8331  0.8452\n",
       "  SD      0.0687  0.0306  0.0926  0.1261  0.0883  0.1428  0.1350\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9206  0.9771  0.8864  0.8864  0.8864  0.8254  0.8254\n",
       "  1       0.9127  0.9807  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  2       0.8968  0.9760  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  3       0.8889  0.9620  0.8864  0.8125  0.8478  0.7606  0.7624\n",
       "  4       0.9127  0.9778  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9206  0.9803  0.8864  0.8864  0.8864  0.8254  0.8254\n",
       "  6       0.9048  0.9811  0.9333  0.8235  0.8750  0.7986  0.8026\n",
       "  7       0.9286  0.9903  0.9111  0.8913  0.9011  0.8452  0.8453\n",
       "  8       0.9286  0.9818  0.9111  0.8913  0.9011  0.8452  0.8453\n",
       "  9       0.9603  0.9956  0.9333  0.9545  0.9438  0.9132  0.9133\n",
       "  Mean    0.9175  0.9803  0.9121  0.8636  0.8865  0.8218  0.8234\n",
       "  SD      0.0188  0.0084  0.0240  0.0430  0.0250  0.0399  0.0392,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.7692  0.8472  0.7500  0.6000  0.6667  0.4935  0.5007\n",
       "  1       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  2       0.8462  0.9722  0.7500  0.7500  0.7500  0.6389  0.6389\n",
       "  3       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  4       0.9231  1.0000  0.7500  1.0000  0.8571  0.8060  0.8216\n",
       "  ...        ...     ...     ...     ...     ...     ...     ...\n",
       "  97      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  98      0.9167  1.0000  1.0000  0.8000  0.8889  0.8235  0.8367\n",
       "  99      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  Mean    0.9303  0.9680  0.9440  0.8859  0.9063  0.8511  0.8613\n",
       "  SD      0.0706  0.0477  0.1121  0.1299  0.0974  0.1512  0.1430\n",
       "  \n",
       "  [102 rows x 7 columns],\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8968  0.9709  0.8636  0.8444  0.8539  0.7742  0.7743\n",
       "  1       0.9286  0.9778  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9365  0.9800  0.9545  0.8750  0.9130  0.8632  0.8652\n",
       "  3       0.9048  0.9665  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9781  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9365  0.9881  0.9091  0.9091  0.9091  0.8603  0.8603\n",
       "  6       0.9048  0.9830  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.9915  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9822  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9683  0.9953  1.0000  0.9184  0.9574  0.9322  0.9344\n",
       "  Mean    0.9238  0.9813  0.9480  0.8537  0.8976  0.8372  0.8411\n",
       "  SD      0.0198  0.0084  0.0381  0.0359  0.0267  0.0423  0.0417,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9127  0.9773  0.8636  0.8837  0.8736  0.8069  0.8070\n",
       "  1       0.9048  0.9762  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  2       0.9206  0.9834  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  3       0.9127  0.9681  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  4       0.9048  0.9715  0.9545  0.8077  0.8750  0.7989  0.8062\n",
       "  5       0.9286  0.9878  0.9091  0.8889  0.8989  0.8437  0.8438\n",
       "  6       0.9286  0.9846  0.9333  0.8750  0.9032  0.8467  0.8478\n",
       "  7       0.9365  0.9868  0.9333  0.8936  0.9130  0.8631  0.8636\n",
       "  8       0.8968  0.9824  0.8444  0.8636  0.8539  0.7742  0.7743\n",
       "  9       0.9365  0.9929  0.9111  0.9111  0.9111  0.8617  0.8617\n",
       "  Mean    0.9183  0.9811  0.9054  0.8700  0.8863  0.8226  0.8242\n",
       "  SD      0.0133  0.0073  0.0374  0.0326  0.0187  0.0288  0.0283,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9365  0.9709  0.9545  0.8750  0.9130  0.8632  0.8652\n",
       "  1       0.9286  0.9532  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  2       0.9127  0.9709  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  3       0.9286  0.9392  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  4       0.9048  0.9818  0.9545  0.8077  0.8750  0.7989  0.8062\n",
       "  5       0.9524  0.9818  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9365  0.9797  0.9556  0.8776  0.9149  0.8644  0.8664\n",
       "  7       0.9524  0.9807  1.0000  0.8824  0.9375  0.8993  0.9039\n",
       "  8       0.9206  0.9523  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9956  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9349  0.9706  0.9593  0.8698  0.9122  0.8607  0.8636\n",
       "  SD      0.0200  0.0164  0.0263  0.0319  0.0269  0.0427  0.0421,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9843  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9763  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.9803  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.9623  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.9814  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.9897  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.9809  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.9898  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9826  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.9945  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.9822  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0084  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9843  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9763  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.9803  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.9623  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.9814  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.9897  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.9809  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.9898  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9826  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.9945  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.9822  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0084  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9206  0.9828  0.9091  0.8696  0.8889  0.8272  0.8277\n",
       "  1       0.8968  0.9762  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.9048  0.9780  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  3       0.9127  0.9611  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  4       0.9127  0.9874  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9603  0.9843  0.9773  0.9149  0.9451  0.9141  0.9153\n",
       "  6       0.8810  0.9775  0.9333  0.7778  0.8485  0.7518  0.7603\n",
       "  7       0.9444  0.9855  0.9778  0.8800  0.9263  0.8819  0.8851\n",
       "  8       0.9127  0.9749  0.9111  0.8542  0.8817  0.8127  0.8137\n",
       "  9       0.9762  0.9947  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9222  0.9802  0.9345  0.8586  0.8945  0.8331  0.8355\n",
       "  SD      0.0279  0.0086  0.0386  0.0433  0.0371  0.0592  0.0584,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8968  0.9623  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  1       0.9127  0.9620  0.8409  0.9024  0.8706  0.8048  0.8060\n",
       "  2       0.8810  0.9748  0.8409  0.8222  0.8315  0.7395  0.7396\n",
       "  3       0.8730  0.9540  0.8409  0.8043  0.8222  0.7235  0.7240\n",
       "  4       0.8968  0.9678  0.9091  0.8163  0.8602  0.7788  0.7817\n",
       "  5       0.9127  0.9770  0.8636  0.8837  0.8736  0.8069  0.8070\n",
       "  6       0.8968  0.9753  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  7       0.9206  0.9794  0.8667  0.9070  0.8864  0.8254  0.8259\n",
       "  8       0.9048  0.9761  0.8444  0.8837  0.8636  0.7905  0.7910\n",
       "  9       0.9444  0.9857  0.9333  0.9130  0.9231  0.8796  0.8797\n",
       "  Mean    0.9040  0.9715  0.8693  0.8610  0.8645  0.7902  0.7909\n",
       "  SD      0.0193  0.0091  0.0301  0.0393  0.0265  0.0415  0.0415,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9206  0.9828  0.9091  0.8696  0.8889  0.8272  0.8277\n",
       "  1       0.8968  0.9762  0.8864  0.8298  0.8571  0.7765  0.7776\n",
       "  2       0.9048  0.9780  0.8864  0.8478  0.8667  0.7926  0.7931\n",
       "  3       0.9127  0.9611  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  4       0.9127  0.9874  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9603  0.9843  0.9773  0.9149  0.9451  0.9141  0.9153\n",
       "  6       0.8810  0.9775  0.9333  0.7778  0.8485  0.7518  0.7603\n",
       "  7       0.9444  0.9855  0.9778  0.8800  0.9263  0.8819  0.8851\n",
       "  8       0.9127  0.9749  0.9111  0.8542  0.8817  0.8127  0.8137\n",
       "  9       0.9762  0.9947  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9222  0.9802  0.9345  0.8586  0.8945  0.8331  0.8355\n",
       "  SD      0.0279  0.0086  0.0386  0.0433  0.0371  0.0592  0.0584,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.8571  0.9593  0.7955  0.7955  0.7955  0.6857  0.6857\n",
       "  1       0.9048  0.9739  0.8409  0.8810  0.8605  0.7882  0.7887\n",
       "  2       0.8968  0.9767  0.8182  0.8780  0.8471  0.7694  0.7705\n",
       "  3       0.8651  0.9537  0.8182  0.8000  0.8090  0.7047  0.7048\n",
       "  4       0.8810  0.9593  0.8864  0.7959  0.8387  0.7448  0.7475\n",
       "  5       0.9206  0.9881  0.8636  0.9048  0.8837  0.8235  0.8240\n",
       "  6       0.8968  0.9772  0.8667  0.8478  0.8571  0.7764  0.7765\n",
       "  7       0.9206  0.9794  0.8667  0.9070  0.8864  0.8254  0.8259\n",
       "  8       0.8810  0.9569  0.8000  0.8571  0.8276  0.7368  0.7379\n",
       "  9       0.9444  0.9874  0.9333  0.9130  0.9231  0.8796  0.8797\n",
       "  Mean    0.8968  0.9712  0.8489  0.8580  0.8529  0.7735  0.7741\n",
       "  SD      0.0256  0.0122  0.0407  0.0445  0.0363  0.0560  0.0559,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.0  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.0  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.0  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.0  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.0  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.0  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.0  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.0  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.0  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.0  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.0  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.0  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.0  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.0  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.0  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.0  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.0  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.0  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.0  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.0  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.0  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.0  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.0  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.0  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.0  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.0  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.0  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.0  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.0  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.0  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.0  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.0  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.0  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9868  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9774  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9286  0.9787  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  3       0.9048  0.9692  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9810  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9603  0.9886  0.9773  0.9149  0.9451  0.9141  0.9153\n",
       "  6       0.9206  0.9870  0.9778  0.8302  0.8980  0.8337  0.8412\n",
       "  7       0.9286  0.9905  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9968  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9310  0.9839  0.9662  0.8573  0.9082  0.8532  0.8575\n",
       "  SD      0.0204  0.0074  0.0208  0.0368  0.0267  0.0430  0.0418,\n",
       "        Accuracy  AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.0  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.0  1.0000  0.8302  0.9072  0.8500  0.8597\n",
       "  2       0.9365  0.0  1.0000  0.8462  0.9167  0.8660  0.8738\n",
       "  3       0.8968  0.0  0.9318  0.8039  0.8632  0.7811  0.7866\n",
       "  4       0.9127  0.0  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  5       0.9524  0.0  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9048  0.0  0.9778  0.8000  0.8800  0.8024  0.8135\n",
       "  7       0.9286  0.0  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.0  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9603  0.0  1.0000  0.9000  0.9474  0.9157  0.9189\n",
       "  Mean    0.9270  0.0  0.9707  0.8459  0.9037  0.8454  0.8510\n",
       "  SD      0.0187  0.0  0.0268  0.0312  0.0242  0.0392  0.0384,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9866  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  1       0.9286  0.9794  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9206  0.9792  0.9318  0.8542  0.8913  0.8290  0.8309\n",
       "  3       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9807  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9683  0.9884  1.0000  0.9167  0.9565  0.9316  0.9338\n",
       "  6       0.9365  0.9872  0.9778  0.8627  0.9167  0.8657  0.8701\n",
       "  7       0.9286  0.9905  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9968  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9325  0.9840  0.9639  0.8618  0.9098  0.8562  0.8599\n",
       "  SD      0.0217  0.0074  0.0252  0.0356  0.0288  0.0460  0.0452,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9365  0.9866  0.9545  0.8750  0.9130  0.8632  0.8652\n",
       "  1       0.9206  0.9802  0.9545  0.8400  0.8936  0.8307  0.8351\n",
       "  2       0.9127  0.9820  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  3       0.9127  0.9676  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  4       0.9127  0.9830  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9524  0.9884  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9365  0.9878  0.9556  0.8776  0.9149  0.8644  0.8664\n",
       "  7       0.9286  0.9894  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9966  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9310  0.9844  0.9548  0.8641  0.9070  0.8523  0.8553\n",
       "  SD      0.0195  0.0072  0.0248  0.0320  0.0262  0.0415  0.0409,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9365  0.9866  0.9545  0.8750  0.9130  0.8632  0.8652\n",
       "  1       0.9206  0.9802  0.9545  0.8400  0.8936  0.8307  0.8351\n",
       "  2       0.9127  0.9820  0.9091  0.8511  0.8791  0.8109  0.8120\n",
       "  3       0.9127  0.9676  0.9318  0.8367  0.8817  0.8129  0.8158\n",
       "  4       0.9127  0.9830  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9524  0.9884  0.9773  0.8958  0.9348  0.8974  0.8995\n",
       "  6       0.9365  0.9878  0.9556  0.8776  0.9149  0.8644  0.8664\n",
       "  7       0.9286  0.9894  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9966  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9310  0.9844  0.9548  0.8641  0.9070  0.8523  0.8553\n",
       "  SD      0.0195  0.0072  0.0248  0.0320  0.0262  0.0415  0.0409,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9866  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  1       0.9286  0.9794  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9206  0.9792  0.9318  0.8542  0.8913  0.8290  0.8309\n",
       "  3       0.9048  0.9684  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9807  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9683  0.9884  1.0000  0.9167  0.9565  0.9316  0.9338\n",
       "  6       0.9365  0.9872  0.9778  0.8627  0.9167  0.8657  0.8701\n",
       "  7       0.9286  0.9905  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9968  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9325  0.9840  0.9639  0.8618  0.9098  0.8562  0.8599\n",
       "  SD      0.0217  0.0074  0.0252  0.0356  0.0288  0.0460  0.0452,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "  0       0.9286  0.9868  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  1       0.9286  0.9774  0.9773  0.8431  0.9053  0.8484  0.8544\n",
       "  2       0.9286  0.9787  0.9545  0.8571  0.9032  0.8469  0.8500\n",
       "  3       0.9048  0.9692  0.9318  0.8200  0.8723  0.7969  0.8010\n",
       "  4       0.9127  0.9810  0.9545  0.8235  0.8842  0.8148  0.8205\n",
       "  5       0.9603  0.9886  0.9773  0.9149  0.9451  0.9141  0.9153\n",
       "  6       0.9206  0.9870  0.9778  0.8302  0.8980  0.8337  0.8412\n",
       "  7       0.9286  0.9905  0.9778  0.8462  0.9072  0.8496  0.8555\n",
       "  8       0.9206  0.9829  0.9333  0.8571  0.8936  0.8305  0.8324\n",
       "  9       0.9762  0.9968  1.0000  0.9375  0.9677  0.9489  0.9501\n",
       "  Mean    0.9310  0.9839  0.9662  0.8573  0.9082  0.8532  0.8575\n",
       "  SD      0.0204  0.0074  0.0208  0.0368  0.0267  0.0430  0.0418],\n",
       " -1,\n",
       " False,\n",
       " False,\n",
       "       Count_3.0  Percentage_11.0  \\\n",
       " 687         0.0              0.0   \n",
       " 547         0.0              0.0   \n",
       " 1762        0.0              0.0   \n",
       " 1715        0.0              0.0   \n",
       " 683         0.0              1.0   \n",
       " ...         ...              ...   \n",
       " 629         0.0              0.0   \n",
       " 1260        0.0              0.0   \n",
       " 970         0.0              0.0   \n",
       " 1864        0.0              0.0   \n",
       " 827         0.0              0.0   \n",
       " \n",
       "       Segment Description_University of Notre Dame  Segment type_mobile  \\\n",
       " 687                                            0.0                  0.0   \n",
       " 547                                            0.0                  0.0   \n",
       " 1762                                           0.0                  0.0   \n",
       " 1715                                           0.0                  0.0   \n",
       " 683                                            0.0                  0.0   \n",
       " ...                                            ...                  ...   \n",
       " 629                                            0.0                  0.0   \n",
       " 1260                                           0.0                  0.0   \n",
       " 970                                            0.0                  0.0   \n",
       " 1864                                           0.0                  0.0   \n",
       " 827                                            0.0                  0.0   \n",
       " \n",
       "       Count_6.0  Count_11.0  Percentage_2.0  Count_4.0  \\\n",
       " 687         0.0         0.0             0.0        0.0   \n",
       " 547         0.0         0.0             0.0        0.0   \n",
       " 1762        0.0         0.0             0.0        0.0   \n",
       " 1715        0.0         0.0             0.0        0.0   \n",
       " 683         0.0         0.0             0.0        0.0   \n",
       " ...         ...         ...             ...        ...   \n",
       " 629         0.0         0.0             0.0        0.0   \n",
       " 1260        0.0         0.0             1.0        0.0   \n",
       " 970         0.0         0.0             0.0        0.0   \n",
       " 1864        0.0         0.0             0.0        1.0   \n",
       " 827         0.0         0.0             0.0        0.0   \n",
       " \n",
       "       Segment Description_Whatsgoodly University  Count_0.0  ...  \\\n",
       " 687                                          0.0        1.0  ...   \n",
       " 547                                          0.0        1.0  ...   \n",
       " 1762                                         0.0        1.0  ...   \n",
       " 1715                                         0.0        0.0  ...   \n",
       " 683                                          0.0        1.0  ...   \n",
       " ...                                          ...        ...  ...   \n",
       " 629                                          0.0        1.0  ...   \n",
       " 1260                                         0.0        0.0  ...   \n",
       " 970                                          0.0        1.0  ...   \n",
       " 1864                                         0.0        0.0  ...   \n",
       " 827                                          0.0        1.0  ...   \n",
       " \n",
       "       ID_multiply_Segment type_mobile  ID_multiply_Count_0.0  \\\n",
       " 687                               0.0           292890.84375   \n",
       " 547                               0.0           292888.06250   \n",
       " 1762                              0.0           292890.21875   \n",
       " 1715                              0.0                0.00000   \n",
       " 683                               0.0           293237.00000   \n",
       " ...                               ...                    ...   \n",
       " 629                               0.0           292888.84375   \n",
       " 1260                              0.0                0.00000   \n",
       " 970                               0.0           292890.56250   \n",
       " 1864                              0.0                0.00000   \n",
       " 827                               0.0           293775.00000   \n",
       " \n",
       "       sin(Percentage)_divide_Count_Power2  ID_divide_Count_Power2  \\\n",
       " 687                          0.000000e+00                0.000000   \n",
       " 547                          0.000000e+00                0.000000   \n",
       " 1762                         0.000000e+00                0.000000   \n",
       " 1715                         5.628085e-07                0.392062   \n",
       " 683                          8.414710e-01           293237.000000   \n",
       " ...                                   ...                     ...   \n",
       " 629                          0.000000e+00                0.000000   \n",
       " 1260                         1.058827e-06                1.210664   \n",
       " 970                          0.000000e+00                0.000000   \n",
       " 1864                         7.507060e-07                0.503461   \n",
       " 827                          0.000000e+00                0.000000   \n",
       " \n",
       "       Answer_No_multiply_Segment type_mobile  ID_multiply_Count_Power2  \\\n",
       " 687                                      0.0              0.000000e+00   \n",
       " 547                                      0.0              0.000000e+00   \n",
       " 1762                                     0.0              0.000000e+00   \n",
       " 1715                                     0.0              2.188145e+11   \n",
       " 683                                      0.0              2.932370e+05   \n",
       " ...                                      ...                       ...   \n",
       " 629                                      0.0              0.000000e+00   \n",
       " 1260                                     0.0              7.086109e+10   \n",
       " 970                                      0.0              0.000000e+00   \n",
       " 1864                                     0.0              1.704018e+11   \n",
       " 827                                      0.0              0.000000e+00   \n",
       " \n",
       "       Count_Power2_divide_tan(ID)  sin(Percentage)_multiply_ID  \\\n",
       " 687                  0.000000e+00                     0.000000   \n",
       " 547                  0.000000e+00                     0.000000   \n",
       " 1762                -0.000000e+00                     0.000000   \n",
       " 1715                 1.466272e+06                123150.656250   \n",
       " 683                  1.091420e+00                246750.421875   \n",
       " ...                           ...                          ...   \n",
       " 629                  0.000000e+00                     0.000000   \n",
       " 1260                 4.094108e+05                 75029.617188   \n",
       " 970                 -0.000000e+00                     0.000000   \n",
       " 1864                 2.125835e+06                127921.664062   \n",
       " 827                  0.000000e+00                     0.000000   \n",
       " \n",
       "       ID_multiply_Answer_No  tan(ID)_multiply_Count_0.0  \n",
       " 687            292890.84375                    0.162052  \n",
       " 547            292888.06250                    0.573888  \n",
       " 1762           292890.21875                   -0.500871  \n",
       " 1715           292897.43750                    0.000000  \n",
       " 683            293237.00000                    0.916237  \n",
       " ...                     ...                         ...  \n",
       " 629            292888.84375                    3.633782  \n",
       " 1260           292897.50000                    0.000000  \n",
       " 970            292890.56250                   -0.121182  \n",
       " 1864           292900.37500                    0.000000  \n",
       " 827                 0.00000                   24.125525  \n",
       " \n",
       " [569 rows x 69 columns],\n",
       " None,\n",
       " 'lightgbm',\n",
       " <MLUsecase.CLASSIFICATION: 1>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_b2 = finalize_model(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf = finalize_model(tune_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_b2 = predict_model(estimator= final_b2, data=test,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = predict_model(estimator= final_rf, data=test,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/Tinder_Millennial_Match/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "0           1\n",
       "1           1\n",
       "2           1\n",
       "3           1\n",
       "4           1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.prediction = pred_rf.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('b2.1.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, target, train_size = 0.7, sampling = True, sample_estimator = None, categorical_features = None,\n",
    "# categorical_imputation = constant, ordinal_features = None, high_cardinality_features = None, \n",
    "# high_cardinality_method = frequency, numeric_features = None, numeric_imputation = mean, date_features = None, \n",
    "# ignore_features = None, normalize = False, normalize_method = zscore, transformation = False, \n",
    "# transformation_method = yeo-johnson, handle_unknown_categorical = True, unknown_categorical_method = least_frequent,\n",
    "# pca = False, pca_method = linear, pca_components = None, ignore_low_variance = False, combine_rare_levels = False, \n",
    "# rare_level_threshold = 0.10, bin_numeric_features = None, remove_outliers = False, outliers_threshold = 0.05, \n",
    "# remove_multicollinearity = False, multicollinearity_threshold = 0.9, remove_perfect_collinearity = False, \n",
    "# create_clusters = False, cluster_iter = 20, polynomial_features = False, polynomial_degree = 2, \n",
    "# trigonometry_features = False, polynomial_threshold = 0.1, group_features = None, group_names = None,\n",
    "# feature_selection = False, feature_selection_threshold = 0.8, feature_interaction = False, feature_ratio = False, \n",
    "# interaction_threshold = 0.01, fix_imbalance = False, fix_imbalance_method = None, data_split_shuffle = True, \n",
    "# folds_shuffle = False, n_jobs = -1, html = True, session_id = None, log_experiment = False, experiment_name = None, \n",
    "# log_plots = False, log_profile = False, log_data = False, silent=False, verbose=True, profile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59be460475794d96999f08e49c7e79e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Processing: ', max=5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 69 and input n_features is 55 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-70a6546de737>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtune_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pycaret\\classification.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(estimator, plot, scale, save, fold, fit_kwargs, groups, use_train_data, verbose)\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \"\"\"\n\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m     return pycaret.internal.tabular.plot_model(\n\u001b[0m\u001b[0;32m   1532\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pycaret\\internal\\tabular.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(estimator, plot, scale, save, fold, fit_kwargs, groups, feature_name, label, use_train_data, verbose, system, display)\u001b[0m\n\u001b[0;32m   7161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7162\u001b[0m                 \u001b[1;31m# execute the plot method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7163\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7164\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7165\u001b[0m                     \u001b[0mplot_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pycaret\\internal\\tabular.py\u001b[0m in \u001b[0;36mauc\u001b[1;34m()\u001b[0m\n\u001b[0;32m   6368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6369\u001b[0m                     \u001b[0mvisualizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mROCAUC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_with_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6370\u001b[1;33m                     show_yellowbrick_plot(\n\u001b[0m\u001b[0;32m   6371\u001b[0m                         \u001b[0mvisualizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvisualizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6372\u001b[0m                         \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pycaret\\internal\\plotting.py\u001b[0m in \u001b[0;36mshow_yellowbrick_plot\u001b[1;34m(visualizer, X_train, y_train, X_test, y_test, name, handle_train, handle_test, scale, save, fit_kwargs, groups, display, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhandle_test\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scoring test/hold-out set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mvisualizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\yellowbrick\\classifier\\rocauc.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;31m# Call super to check if fitted and to compute self.score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;31m# NOTE: this sets score to the base score if neither macro nor micro\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROCAUC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m# Compute the predictions for the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\yellowbrick\\classifier\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;31m# This method implements ScoreVisualizer (do not call super).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0mscore_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mscore_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 69 and input n_features is 55 "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(estimator=tune_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
